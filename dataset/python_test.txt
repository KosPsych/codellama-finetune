def _bookmarks(self):
            '''Parse .hg/bookmarks file and return a dictionary

            Bookmarks are stored as {HASH}\\s{NAME}\\n (localtags format) values
            in the .hg/bookmarks file. They are read returned as a dictionary
            with name => hash values.
            '''
            try:
                bookmarks = {}
                for line in self.opener('bookmarks'):
                    sha, refspec = line.strip().split(' ', 1)
                    bookmarks[refspec] = super(bookmark_repo, self).lookup(sha)
            except:
                pass
            return bookmarks
###END###
def _bookmarkcurrent(self):
            '''Get the current bookmark

            If we use gittishsh branches we have a current bookmark that
            we are on. This function returns the name of the bookmark. It
            is stored in .hg/bookmarks.current
            '''
            mark = None
            if os.path.exists(self.join('bookmarks.current')):
                file = self.opener('bookmarks.current')
                # No readline() in posixfile_nt, reading everything is cheap
                mark = (file.readlines() or [''])[0]
                if mark == '':
                    mark = None
                file.close()
            return mark
###END###
def rollback(self):
            if os.path.exists(self.join('undo.bookmarks')):
                util.rename(self.join('undo.bookmarks'), self.join('bookmarks'))
            return super(bookmark_repo, self).rollback()
###END###
def lookup(self, key):
            if key in self._bookmarks:
                key = self._bookmarks[key]
            return super(bookmark_repo, self).lookup(key)
###END###
def _bookmarksupdate(self, parents, node):
            marks = self._bookmarks
            update = False
            if ui.configbool('bookmarks', 'track.current'):
                mark = self._bookmarkcurrent
                if mark and marks[mark] in parents:
                    marks[mark] = node
                    update = True
            else:
                for mark, n in marks.items():
                    if n in parents:
                        marks[mark] = node
                        update = True
            if update:
                write(self)
###END###
def commitctx(self, ctx, error=False):
            """Add a revision to the repository and
            move the bookmark"""
            wlock = self.wlock() # do both commit and bookmark with lock held
            try:
                node  = super(bookmark_repo, self).commitctx(ctx, error)
                if node is None:
                    return None
                parents = self.changelog.parents(node)
                if parents[1] == nullid:
                    parents = (parents[0],)

                self._bookmarksupdate(parents, node)
                return node
            finally:
                wlock.release()
###END###
def addchangegroup(self, source, srctype, url, emptyok=False):
            parents = self.dirstate.parents()

            result = super(bookmark_repo, self).addchangegroup(
                source, srctype, url, emptyok)
            if result > 1:
                # We have more heads than before
                return result
            node = self.changelog.tip()

            self._bookmarksupdate(parents, node)
            return result
###END###
def _findtags(self):
            """Merge bookmarks with normal tags"""
            (tags, tagtypes) = super(bookmark_repo, self)._findtags()
            tags.update(self._bookmarks)
            return (tags, tagtypes)
###END###
def __init__(self, name):
        self.name = name
        self.args = []
        self.opts = {}
###END###
def __bytes__(self):
        cmd = b"hg " + self.name
        if self.opts:
            for k, values in sorted(pycompat.iteritems(self.opts)):
                for v in values:
                    if v:
                        if isinstance(v, int):
                            fmt = b' %s %d'
                        else:
                            fmt = b' %s %s'

                        cmd += fmt % (k, v)
                    else:
                        cmd += b" %s" % (k,)
        if self.args:
            cmd += b" "
            cmd += b" ".join(self.args)
        return cmd
###END###
def append(self, value):
        self.args.append(value)
###END###
def extend(self, values):
        self.args.extend(values)
###END###
def __setitem__(self, key, value):
        values = self.opts.setdefault(key, [])
        values.append(value)
###END###
def __and__(self, other):
        return AndCommand(self, other)
###END###
def __init__(self, left, right):
        self.left = left
        self.right = right
###END###
def __str__(self):
        return b"%s && %s" % (self.left, self.right)
###END###
def __and__(self, other):
        return AndCommand(self, other)
###END###
def __init__(self, cia, ctx):
        self.cia = cia
        self.ctx = ctx
        self.url = self.cia.url
        if self.url:
            self.url += self.cia.root
###END###
def fileelem(self, path, uri, action):
        if uri:
            uri = ' uri=%s' % saxutils.quoteattr(uri)
        return '<file%s action=%s>%s</file>' % (
            uri, saxutils.quoteattr(action), saxutils.escape(path))
###END###
def fileelems(self):
        n = self.ctx.node()
        f = self.cia.repo.status(self.ctx.p1().node(), n)
        url = self.url or ''
        if url and url[-1] == '/':
            url = url[:-1]
        elems = []
        for path in f[0]:
            uri = '%s/diff/%s/%s' % (url, short(n), path)
            elems.append(self.fileelem(path, url and uri, 'modify'))
        for path in f[1]:
            # TODO: copy/rename ?
            uri = '%s/file/%s/%s' % (url, short(n), path)
            elems.append(self.fileelem(path, url and uri, 'add'))
        for path in f[2]:
            elems.append(self.fileelem(path, '', 'remove'))

        return '\n'.join(elems)
###END###
def sourceelem(self, project, module=None, branch=None):
        msg = ['<source>', '<project>%s</project>' % saxutils.escape(project)]
        if module:
            msg.append('<module>%s</module>' % saxutils.escape(module))
        if branch:
            msg.append('<branch>%s</branch>' % saxutils.escape(branch))
        msg.append('</source>')

        return '\n'.join(msg)
###END###
def diffstat(self):
        class patchbuf(object):
            def __init__(self):
                self.lines = []
                # diffstat is stupid
                self.name = 'cia'
            def write(self, data):
                self.lines += data.splitlines(True)
            def close(self):
                pass

        n = self.ctx.node()
        pbuf = patchbuf()
        cmdutil.export(self.cia.repo, [n], fp=pbuf)
        return patch.diffstat(pbuf.lines) or ''
###END###
def logmsg(self):
        diffstat = self.cia.diffstat and self.diffstat() or ''
        self.cia.ui.pushbuffer()
        self.cia.templater.show(self.ctx, changes=self.ctx.changeset(),
                                baseurl=self.cia.ui.config('web', 'baseurl'),
                                url=self.url, diffstat=diffstat,
                                webroot=self.cia.root)
        return self.cia.ui.popbuffer()
###END###
def xml(self):
        n = short(self.ctx.node())
        src = self.sourceelem(self.cia.project, module=self.cia.module,
                              branch=self.ctx.branch())
        # unix timestamp
        dt = self.ctx.date()
        timestamp = dt[0]

        author = saxutils.escape(self.ctx.user())
        rev = '%d:%s' % (self.ctx.rev(), n)
        log = saxutils.escape(self.logmsg())

        url = self.url
        if url and url[-1] == '/':
            url = url[:-1]
        url = url and '<url>%s/rev/%s</url>' % (saxutils.escape(url), n) or ''

        msg = """
<message>
  <generator>
    <name>Mercurial (hgcia)</name>
    <version>%s</version>
    <url>%s</url>
    <user>%s</user>
  </generator>
  %s
  <body>
    <commit>
      <author>%s</author>
      <version>%s</version>
      <log>%s</log>
      %s
      <files>%s</files>
    </commit>
  </body>
  <timestamp>%d</timestamp>
</message>
""" % \
            (HGCIA_VERSION, saxutils.escape(HGCIA_URL),
            saxutils.escape(self.cia.user), src, author, rev, log, url,
            self.fileelems(), timestamp)

        return msg
###END###
def __init__(self, ui, repo):
        self.ui = ui
        self.repo = repo

        self.ciaurl = self.ui.config('cia', 'url', 'http://cia.vc')
        self.user = self.ui.config('cia', 'user')
        self.project = self.ui.config('cia', 'project')
        self.module = self.ui.config('cia', 'module')
        self.diffstat = self.ui.configbool('cia', 'diffstat')
        self.emailfrom = self.ui.config('email', 'from')
        self.dryrun = self.ui.configbool('cia', 'test')
        self.url = self.ui.config('web', 'baseurl')
        # Default to -1 for backward compatibility
        self.stripcount = int(self.ui.config('cia', 'strip', -1))
        self.root = self.strip(self.repo.root)

        style = self.ui.config('cia', 'style')
        template = self.ui.config('cia', 'template')
        if not template:
            template = self.diffstat and self.dstemplate or self.deftemplate
        template = templater.parsestring(template, quoted=False)
        t = cmdutil.changeset_templater(self.ui, self.repo, False, None,
                                        style, False)
        t.use_template(template)
        self.templater = t
###END###
def strip(self, path):
        '''strip leading slashes from local path, turn into web-safe path.'''

        path = util.pconvert(path)
        count = self.stripcount
        if count < 0:
            return ''
        while count > 0:
            c = path.find('/')
            if c == -1:
                break
            path = path[c + 1:]
            count -= 1
        return path
###END###
def sendrpc(self, msg):
        srv = xmlrpclib.Server(self.ciaurl)
        res = srv.hub.deliver(msg)
        if res is not True and res != 'queued.':
            raise util.Abort(_('%s returned an error: %s') %
                             (self.ciaurl, res))
###END###
def sendemail(self, address, data):
        p = email.Parser.Parser()
        msg = p.parsestr(data)
        msg['Date'] = util.datestr(format="%a, %d %b %Y %H:%M:%S %1%2")
        msg['To'] = address
        msg['From'] = self.emailfrom
        msg['Subject'] = 'DeliverXML'
        msg['Content-type'] = 'text/xml'
        msgtext = msg.as_string()

        self.ui.status(_('hgcia: sending update to %s\n') % address)
        mail.sendmail(self.ui, util.email(self.emailfrom),
                      [address], msgtext)
###END###
def __init__(self):
                self.lines = []
                # diffstat is stupid
                self.name = 'cia'
###END###
def write(self, data):
                self.lines += data.splitlines(True)
###END###
def close(self):
                pass
###END###
def _extrasetup(self, name, func, fmtopic=None, csettopic=None):
        """Called with decorator arguments to register a show view.

        ``name`` is the sub-command name.

        ``func`` is the function being decorated.

        ``fmtopic`` is the topic in the style that will be rendered for
        this view.

        ``csettopic`` is the topic in the style to be used for a changeset
        printer.

        If ``fmtopic`` is specified, the view function will receive a
        formatter instance. If ``csettopic`` is specified, the view
        function will receive a changeset printer.
        """
        func._fmtopic = fmtopic
        func._csettopic = csettopic
###END###
def copynewmetadatatoold(self):
        for key in list(self.metadata.keys()):
            newkey = key.replace(b'new:', b'old:')
            self.metadata[newkey] = self.metadata[key]
###END###
def addoldmode(self, value):
        self.oldProperties[b'unix:filemode'] = value
###END###
def addnewmode(self, value):
        self.newProperties[b'unix:filemode'] = value
###END###
def addhunk(self, hunk):
        if not isinstance(hunk, phabhunk):
            raise error.Abort(b'phabchange.addhunk only takes phabhunks')
        self.hunks.append(pycompat.byteskwargs(attr.asdict(hunk)))
        # It's useful to include these stats since the Phab web UI shows them,
        # and uses them to estimate how large a change a Revision is. Also used
        # in email subjects for the [+++--] bit.
        self.addLines += hunk.addLines
        self.delLines += hunk.delLines
###END###
def addchange(self, change):
        if not isinstance(change, phabchange):
            raise error.Abort(b'phabdiff.addchange only takes phabchanges')
        self.changes[change.currentPath] = pycompat.byteskwargs(
            attr.asdict(change)
        )
###END###
def __init__(self, path, cmdline, isgui):
        # We can't pass non-ASCII through docstrings (and path is
        # in an unknown encoding anyway), but avoid double separators on
        # Windows
        docpath = stringutil.escapestr(path).replace(b'\\\\', b'\\')
        self.__doc__ %= {'path': pycompat.sysstr(stringutil.uirepr(docpath))}
        self._cmdline = cmdline
        self._isgui = isgui
###END###
def __call__(self, ui, repo, *pats, **opts):
        opts = pycompat.byteskwargs(opts)
        options = b' '.join(map(procutil.shellquote, opts[b'option']))
        if options:
            options = b' ' + options
        return dodiff(
            ui, repo, self._cmdline + options, pats, opts, guitool=self._isgui
        )
###END###
def __init__(self):
        self.sections = {}
###END###
def __contains__(self, section):
        return section in self.sections
###END###
def __iter__(self):
        return iter(sorted(self.sections))
###END###
def addtitleditem(self, section, title, paragraphs):
        """Add a titled release note entry."""
        self.sections.setdefault(section, ([], []))
        self.sections[section][0].append((title, paragraphs))
###END###
def addnontitleditem(self, section, paragraphs):
        """Adds a non-titled release note entry.

        Will be rendered as a bullet point.
        """
        self.sections.setdefault(section, ([], []))
        self.sections[section][1].append(paragraphs)
###END###
def titledforsection(self, section):
        """Returns titled entries in a section.

        Returns a list of (title, paragraphs) tuples describing sub-sections.
        """
        return self.sections.get(section, ([], []))[0]
###END###
def nontitledforsection(self, section):
        """Returns non-titled, bulleted paragraphs in a section."""
        return self.sections.get(section, ([], []))[1]
###END###
def hastitledinsection(self, section, title):
        return any(t[0] == title for t in self.titledforsection(section))
###END###
def merge(self, ui, other):
        """Merge another instance into this one.

        This is used to combine multiple sources of release notes together.
        """
        if not fuzz:
            ui.warn(
                _(
                    b"module 'fuzzywuzzy' not found, merging of similar "
                    b"releasenotes is disabled\n"
                )
            )

        for section in other:
            existingnotes = converttitled(
                self.titledforsection(section)
            ) + convertnontitled(self.nontitledforsection(section))
            for title, paragraphs in other.titledforsection(section):
                if self.hastitledinsection(section, title):
                    # TODO prompt for resolution if different and running in
                    # interactive mode.
                    ui.write(
                        _(b'%s already exists in %s section; ignoring\n')
                        % (title, section)
                    )
                    continue

                incoming_str = converttitled([(title, paragraphs)])[0]
                if section == b'fix':
                    issue = getissuenum(incoming_str)
                    if issue:
                        if findissue(ui, existingnotes, issue):
                            continue

                if similar(ui, existingnotes, incoming_str):
                    continue

                self.addtitleditem(section, title, paragraphs)

            for paragraphs in other.nontitledforsection(section):
                if paragraphs in self.nontitledforsection(section):
                    continue

                incoming_str = convertnontitled([paragraphs])[0]
                if section == b'fix':
                    issue = getissuenum(incoming_str)
                    if issue:
                        if findissue(ui, existingnotes, issue):
                            continue

                if similar(ui, existingnotes, incoming_str):
                    continue

                self.addnontitleditem(section, paragraphs)
###END###
def __init__(self, ui, repo=None):
        if repo:
            sections = util.sortdict(DEFAULT_SECTIONS)
            custom_sections = getcustomadmonitions(repo)
            if custom_sections:
                sections.update(custom_sections)
            self._sections = list(pycompat.iteritems(sections))
        else:
            self._sections = list(DEFAULT_SECTIONS)
###END###
def __iter__(self):
        return iter(self._sections)
###END###
def names(self):
        return [t[0] for t in self._sections]
###END###
def sectionfromtitle(self, title):
        for name, value in self._sections:
            if value == title:
                return name

        return None
###END###
def __init__(self, ui, repo, opts):
        self.ui = ui
        self.opts = opts

        if ui.quiet:
            datefunc = dateutil.shortdate
        else:
            datefunc = dateutil.datestr
        datefunc = util.cachefunc(datefunc)
        getctx = util.cachefunc(lambda x: repo[x[0]])
        hexfunc = self._hexfunc

        # special handling working copy "changeset" and "rev" functions
        if self.opts.get(b'rev') == b'wdir()':
            orig = hexfunc
            hexfunc = lambda x: None if x is None else orig(x)
            wnode = hexfunc(repo[b'.'].node()) + b'+'
            wrev = b'%d' % repo[b'.'].rev()
            wrevpad = b''
            if not opts.get(b'changeset'):  # only show + if changeset is hidden
                wrev += b'+'
                wrevpad = b' '
            revenc = lambda x: wrev if x is None else (b'%d' % x) + wrevpad

            def csetenc(x):
                if x is None:
                    return wnode
                return pycompat.bytestr(x) + b' '

        else:
            revenc = csetenc = pycompat.bytestr

        # opt name, separator, raw value (for json/plain), encoder (for plain)
        opmap = [
            (b'user', b' ', lambda x: getctx(x).user(), ui.shortuser),
            (b'number', b' ', lambda x: getctx(x).rev(), revenc),
            (b'changeset', b' ', lambda x: hexfunc(x[0]), csetenc),
            (b'date', b' ', lambda x: getctx(x).date(), datefunc),
            (b'file', b' ', lambda x: x[2], pycompat.bytestr),
            (b'line_number', b':', lambda x: x[1] + 1, pycompat.bytestr),
        ]
        fieldnamemap = {b'number': b'rev', b'changeset': b'node'}
        funcmap = [
            (get, sep, fieldnamemap.get(op, op), enc)
            for op, sep, get, enc in opmap
            if opts.get(op)
        ]
        # no separator for first column
        funcmap[0] = list(funcmap[0])
        funcmap[0][1] = b''
        self.funcmap = funcmap
###END###
def write(self, annotatedresult, lines=None, existinglines=None):
        """(annotateresult, [str], set([rev, linenum])) -> None. write output.
        annotateresult can be [(node, linenum, path)], or [(node, linenum)]
        """
        pieces = []  # [[str]]
        maxwidths = []  # [int]

        # calculate padding
        for f, sep, name, enc in self.funcmap:
            l = [enc(f(x)) for x in annotatedresult]
            pieces.append(l)
            if name in [b'node', b'date']:  # node and date has fixed size
                l = l[:1]
            widths = pycompat.maplist(encoding.colwidth, set(l))
            maxwidth = max(widths) if widths else 0
            maxwidths.append(maxwidth)

        # buffered output
        result = b''
        for i in pycompat.xrange(len(annotatedresult)):
            for j, p in enumerate(pieces):
                sep = self.funcmap[j][1]
                padding = b' ' * (maxwidths[j] - len(p[i]))
                result += sep + padding + p[i]
            if lines:
                if existinglines is None:
                    result += b': ' + lines[i]
                else:  # extra formatting showing whether a line exists
                    key = (annotatedresult[i][0], annotatedresult[i][1])
                    if key in existinglines:
                        result += b':  ' + lines[i]
                    else:
                        result += b': ' + self.ui.label(
                            b'-' + lines[i], b'diff.deleted'
                        )

            if result[-1:] != b'\n':
                result += b'\n'

        self.ui.write(result)
###END###
def _hexfunc(self):
        if self.ui.debugflag or self.opts.get(b'long_hash'):
            return hex
        else:
            return short
###END###
def end(self):
        pass
###END###
def __init__(self, ui, repo, opts):
        super(jsonformatter, self).__init__(ui, repo, opts)
        self.ui.write(b'[')
        self.needcomma = False
###END###
def write(self, annotatedresult, lines=None, existinglines=None):
        if annotatedresult:
            self._writecomma()

        pieces = [
            (name, pycompat.maplist(f, annotatedresult))
            for f, sep, name, enc in self.funcmap
        ]
        if lines is not None:
            pieces.append((b'line', lines))
        pieces.sort()

        seps = [b','] * len(pieces[:-1]) + [b'']

        result = b''
        lasti = len(annotatedresult) - 1
        for i in pycompat.xrange(len(annotatedresult)):
            result += b'\n {\n'
            for j, p in enumerate(pieces):
                k, vs = p
                result += b'  "%s": %s%s\n' % (
                    k,
                    templatefilters.json(vs[i], paranoid=False),
                    seps[j],
                )
            result += b' }%s' % (b'' if i == lasti else b',')
        if lasti >= 0:
            self.needcomma = True

        self.ui.write(result)
###END###
def _writecomma(self):
        if self.needcomma:
            self.ui.write(b',')
            self.needcomma = False
###END###
def _hexfunc(self):
        return hex
###END###
def end(self):
        self.ui.write(b'\n]\n')
###END###
def __init__(self, repo, node, path):
        self._node = node
        self._path = path
        self._repo = repo
###END###
def node(self):
        return self._node
###END###
def path(self):
        return self._path
###END###
def _fctx(self):
        return context.resolvefctx(self._repo, self._node, self._path)
###END###
def __getattr__(self, name):
        return getattr(self._fctx, name)
###END###
def __init__(self, **entries):
        self.synthetic = False
        self.__dict__.update(entries)
###END###
def __repr__(self):
        items = ("%s=%r" % (k, self.__dict__[k]) for k in sorted(self.__dict__))
        return "%s(%s)" % (type(self).__name__, ", ".join(items))
###END###
def __init__(self, **entries):
        self.id = None
        self.synthetic = False
        self.__dict__.update(entries)
###END###
def __repr__(self):
        items = (
            b"%s=%r" % (k, self.__dict__[k]) for k in sorted(self.__dict__)
        )
        return b"%s(%s)" % (type(self).__name__, b", ".join(items))
###END###
def __init__(self, ui, repotype, path=None, revs=None):
        common.converter_source.__init__(self, ui, repotype, path, revs)
        if revs and len(revs) > 1:
            raise error.Abort(
                _(
                    b'monotone source does not support specifying '
                    b'multiple revs'
                )
            )
        common.commandline.__init__(self, ui, b'mtn')

        self.ui = ui
        self.path = path
        self.automatestdio = False
        self.revs = revs

        norepo = common.NoRepo(
            _(b"%s does not look like a monotone repository") % path
        )
        if not os.path.exists(os.path.join(path, b'_MTN')):
            # Could be a monotone repository (SQLite db file)
            try:
                f = open(path, b'rb')
                header = f.read(16)
                f.close()
            except IOError:
                header = b''
            if header != b'SQLite format 3\x00':
                raise norepo

        # regular expressions for parsing monotone output
        space = br'\s*'
        name = br'\s+"((?:\\"|[^"])*)"\s*'
        value = name
        revision = br'\s+\[(\w+)\]\s*'
        lines = br'(?:.|\n)+'

        self.dir_re = re.compile(space + b"dir" + name)
        self.file_re = re.compile(
            space + b"file" + name + b"content" + revision
        )
        self.add_file_re = re.compile(
            space + b"add_file" + name + b"content" + revision
        )
        self.patch_re = re.compile(
            space + b"patch" + name + b"from" + revision + b"to" + revision
        )
        self.rename_re = re.compile(space + b"rename" + name + b"to" + name)
        self.delete_re = re.compile(space + b"delete" + name)
        self.tag_re = re.compile(space + b"tag" + name + b"revision" + revision)
        self.cert_re = re.compile(
            lines + space + b"name" + name + b"value" + value
        )

        attr = space + b"file" + lines + space + b"attr" + space
        self.attr_execute_re = re.compile(
            attr + b'"mtn:execute"' + space + b'"true"'
        )

        # cached data
        self.manifest_rev = None
        self.manifest = None
        self.files = None
        self.dirs = None

        common.checktool(b'mtn', abort=False)
###END###
def mtnrun(self, *args, **kwargs):
        if self.automatestdio:
            return self.mtnrunstdio(*args, **kwargs)
        else:
            return self.mtnrunsingle(*args, **kwargs)
###END###
def mtnrunsingle(self, *args, **kwargs):
        kwargs['d'] = self.path
        return self.run0(b'automate', *args, **kwargs)
###END###
def mtnrunstdio(self, *args, **kwargs):
        # Prepare the command in automate stdio format
        kwargs = pycompat.byteskwargs(kwargs)
        command = []
        for k, v in pycompat.iteritems(kwargs):
            command.append(b"%d:%s" % (len(k), k))
            if v:
                command.append(b"%d:%s" % (len(v), v))
        if command:
            command.insert(0, b'o')
            command.append(b'e')

        command.append(b'l')
        for arg in args:
            command.append(b"%d:%s" % (len(arg), arg))
        command.append(b'e')
        command = b''.join(command)

        self.ui.debug(b"mtn: sending '%s'\n" % command)
        self.mtnwritefp.write(command)
        self.mtnwritefp.flush()

        return self.mtnstdioreadcommandoutput(command)
###END###
def mtnstdioreadpacket(self):
        read = None
        commandnbr = b''
        while read != b':':
            read = self.mtnreadfp.read(1)
            if not read:
                raise error.Abort(_(b'bad mtn packet - no end of commandnbr'))
            commandnbr += read
        commandnbr = commandnbr[:-1]

        stream = self.mtnreadfp.read(1)
        if stream not in b'mewptl':
            raise error.Abort(
                _(b'bad mtn packet - bad stream type %s') % stream
            )

        read = self.mtnreadfp.read(1)
        if read != b':':
            raise error.Abort(_(b'bad mtn packet - no divider before size'))

        read = None
        lengthstr = b''
        while read != b':':
            read = self.mtnreadfp.read(1)
            if not read:
                raise error.Abort(_(b'bad mtn packet - no end of packet size'))
            lengthstr += read
        try:
            length = pycompat.long(lengthstr[:-1])
        except TypeError:
            raise error.Abort(
                _(b'bad mtn packet - bad packet size %s') % lengthstr
            )

        read = self.mtnreadfp.read(length)
        if len(read) != length:
            raise error.Abort(
                _(
                    b"bad mtn packet - unable to read full packet "
                    b"read %s of %s"
                )
                % (len(read), length)
            )

        return (commandnbr, stream, length, read)
###END###
def mtnstdioreadcommandoutput(self, command):
        retval = []
        while True:
            commandnbr, stream, length, output = self.mtnstdioreadpacket()
            self.ui.debug(
                b'mtn: read packet %s:%s:%d\n' % (commandnbr, stream, length)
            )

            if stream == b'l':
                # End of command
                if output != b'0':
                    raise error.Abort(
                        _(b"mtn command '%s' returned %s") % (command, output)
                    )
                break
            elif stream in b'ew':
                # Error, warning output
                self.ui.warn(_(b'%s error:\n') % self.command)
                self.ui.warn(output)
            elif stream == b'p':
                # Progress messages
                self.ui.debug(b'mtn: ' + output)
            elif stream == b'm':
                # Main stream - command output
                retval.append(output)

        return b''.join(retval)
###END###
def mtnloadmanifest(self, rev):
        if self.manifest_rev == rev:
            return
        self.manifest = self.mtnrun(b"get_manifest_of", rev).split(b"\n\n")
        self.manifest_rev = rev
        self.files = {}
        self.dirs = {}

        for e in self.manifest:
            m = self.file_re.match(e)
            if m:
                attr = b""
                name = m.group(1)
                node = m.group(2)
                if self.attr_execute_re.match(e):
                    attr += b"x"
                self.files[name] = (node, attr)
            m = self.dir_re.match(e)
            if m:
                self.dirs[m.group(1)] = True
###END###
def mtnisfile(self, name, rev):
        # a non-file could be a directory or a deleted or renamed file
        self.mtnloadmanifest(rev)
        return name in self.files
###END###
def mtnisdir(self, name, rev):
        self.mtnloadmanifest(rev)
        return name in self.dirs
###END###
def mtngetcerts(self, rev):
        certs = {
            b"author": b"<missing>",
            b"date": b"<missing>",
            b"changelog": b"<missing>",
            b"branch": b"<missing>",
        }
        certlist = self.mtnrun(b"certs", rev)
        # mtn < 0.45:
        #   key "test@selenic.com"
        # mtn >= 0.45:
        #   key [ff58a7ffb771907c4ff68995eada1c4da068d328]
        certlist = re.split(br'\n\n {6}key ["\[]', certlist)
        for e in certlist:
            m = self.cert_re.match(e)
            if m:
                name, value = m.groups()
                value = value.replace(br'\"', b'"')
                value = value.replace(br'\\', b'\\')
                certs[name] = value
        # Monotone may have subsecond dates: 2005-02-05T09:39:12.364306
        # and all times are stored in UTC
        certs[b"date"] = certs[b"date"].split(b'.')[0] + b" UTC"
        return certs
###END###
def getheads(self):
        if not self.revs:
            return self.mtnrun(b"leaves").splitlines()
        else:
            return self.revs
###END###
def getchanges(self, rev, full):
        if full:
            raise error.Abort(
                _(b"convert from monotone does not support --full")
            )
        revision = self.mtnrun(b"get_revision", rev).split(b"\n\n")
        files = {}
        ignoremove = {}
        renameddirs = []
        copies = {}
        for e in revision:
            m = self.add_file_re.match(e)
            if m:
                files[m.group(1)] = rev
                ignoremove[m.group(1)] = rev
            m = self.patch_re.match(e)
            if m:
                files[m.group(1)] = rev
            # Delete/rename is handled later when the convert engine
            # discovers an IOError exception from getfile,
            # but only if we add the "from" file to the list of changes.
            m = self.delete_re.match(e)
            if m:
                files[m.group(1)] = rev
            m = self.rename_re.match(e)
            if m:
                toname = m.group(2)
                fromname = m.group(1)
                if self.mtnisfile(toname, rev):
                    ignoremove[toname] = 1
                    copies[toname] = fromname
                    files[toname] = rev
                    files[fromname] = rev
                elif self.mtnisdir(toname, rev):
                    renameddirs.append((fromname, toname))

        # Directory renames can be handled only once we have recorded
        # all new files
        for fromdir, todir in renameddirs:
            renamed = {}
            for tofile in self.files:
                if tofile in ignoremove:
                    continue
                if tofile.startswith(todir + b'/'):
                    renamed[tofile] = fromdir + tofile[len(todir) :]
                    # Avoid chained moves like:
                    # d1(/a) => d3/d1(/a)
                    # d2 => d3
                    ignoremove[tofile] = 1
            for tofile, fromfile in renamed.items():
                self.ui.debug(
                    b"copying file in renamed directory from '%s' to '%s'"
                    % (fromfile, tofile),
                    b'\n',
                )
                files[tofile] = rev
                copies[tofile] = fromfile
            for fromfile in renamed.values():
                files[fromfile] = rev

        return (files.items(), copies, set())
###END###
def getfile(self, name, rev):
        if not self.mtnisfile(name, rev):
            return None, None
        try:
            data = self.mtnrun(b"get_file_of", name, r=rev)
        except Exception:
            return None, None
        self.mtnloadmanifest(rev)
        node, attr = self.files.get(name, (None, b""))
        return data, attr
###END###
def getcommit(self, rev):
        extra = {}
        certs = self.mtngetcerts(rev)
        if certs.get(b'suspend') == certs[b"branch"]:
            extra[b'close'] = b'1'
        dateformat = b"%Y-%m-%dT%H:%M:%S"
        return common.commit(
            author=certs[b"author"],
            date=dateutil.datestr(dateutil.strdate(certs[b"date"], dateformat)),
            desc=certs[b"changelog"],
            rev=rev,
            parents=self.mtnrun(b"parents", rev).splitlines(),
            branch=certs[b"branch"],
            extra=extra,
        )
###END###
def gettags(self):
        tags = {}
        for e in self.mtnrun(b"tags").split(b"\n\n"):
            m = self.tag_re.match(e)
            if m:
                tags[m.group(1)] = m.group(2)
        return tags
###END###
def getchangedfiles(self, rev, i):
        # This function is only needed to support --filemap
        # ... and we don't support that
        raise NotImplementedError
###END###
def before(self):
        # Check if we have a new enough version to use automate stdio
        try:
            versionstr = self.mtnrunsingle(b"interface_version")
            version = float(versionstr)
        except Exception:
            raise error.Abort(
                _(b"unable to determine mtn automate interface version")
            )

        if version >= 12.0:
            self.automatestdio = True
            self.ui.debug(
                b"mtn automate version %f - using automate stdio\n" % version
            )

            # launch the long-running automate stdio process
            self.mtnwritefp, self.mtnreadfp = self._run2(
                b'automate', b'stdio', b'-d', self.path
            )
            # read the headers
            read = self.mtnreadfp.readline()
            if read != b'format-version: 2\n':
                raise error.Abort(
                    _(b'mtn automate stdio header unexpected: %s') % read
                )
            while read != b'\n':
                read = self.mtnreadfp.readline()
                if not read:
                    raise error.Abort(
                        _(
                            b"failed to reach end of mtn automate "
                            b"stdio headers"
                        )
                    )
        else:
            self.ui.debug(
                b"mtn automate version %s - not using automate stdio "
                b"(automate >= 12.0 - mtn >= 0.46 is needed)\n" % version
            )
###END###
def after(self):
        if self.automatestdio:
            self.mtnwritefp.close()
            self.mtnwritefp = None
            self.mtnreadfp.close()
            self.mtnreadfp = None
###END###
def __init__(self, p):
        self.copyfrom_path = p.copyfrom_path
        self.copyfrom_rev = p.copyfrom_rev
        self.action = p.action
###END###
def __init__(self, stdout):
        self._stdout = stdout
###END###
def __iter__(self):
        while True:
            try:
                entry = pickle.load(self._stdout)
            except EOFError:
                raise error.Abort(
                    _(
                        b'Mercurial failed to run itself, check'
                        b' hg executable is in PATH'
                    )
                )
            try:
                orig_paths, revnum, author, date, message = entry
            except (TypeError, ValueError):
                if entry is None:
                    break
                raise error.Abort(_(b"log stream exception '%s'") % entry)
            yield entry
###END###
def close(self):
        if self._stdout:
            self._stdout.close()
            self._stdout = None
###END###
def __init__(
        self,
        url,
        paths,
        start,
        end,
        limit=0,
        discover_changed_paths=True,
        strict_node_history=False,
    ):
        def receiver(orig_paths, revnum, author, date, message, pool):
            paths = {}
            if orig_paths is not None:
                for k, v in pycompat.iteritems(orig_paths):
                    paths[k] = changedpath(v)
            self.append((paths, revnum, author, date, message))

        # Use an ra of our own so that our parent can consume
        # our results without confusing the server.
        t = transport.SvnRaTransport(url=url)
        svn.ra.get_log(
            t.ra,
            paths,
            start,
            end,
            limit,
            discover_changed_paths,
            strict_node_history,
            receiver,
        )
###END###
def close(self):
        pass
###END###
def __init__(self, ui, repotype, url, revs=None):
        super(svn_source, self).__init__(ui, repotype, url, revs=revs)

        init_fsencoding()
        if not (
            url.startswith(b'svn://')
            or url.startswith(b'svn+ssh://')
            or (
                os.path.exists(url)
                and os.path.exists(os.path.join(url, b'.svn'))
            )
            or issvnurl(ui, url)
        ):
            raise NoRepo(
                _(b"%s does not look like a Subversion repository") % url
            )
        if svn is None:
            raise MissingTool(_(b'could not load Subversion python bindings'))

        try:
            version = svn.core.SVN_VER_MAJOR, svn.core.SVN_VER_MINOR
            if version < (1, 4):
                raise MissingTool(
                    _(
                        b'Subversion python bindings %d.%d found, '
                        b'1.4 or later required'
                    )
                    % version
                )
        except AttributeError:
            raise MissingTool(
                _(
                    b'Subversion python bindings are too old, 1.4 '
                    b'or later required'
                )
            )

        self.lastrevs = {}

        latest = None
        try:
            # Support file://path@rev syntax. Useful e.g. to convert
            # deleted branches.
            at = url.rfind(b'@')
            if at >= 0:
                latest = int(url[at + 1 :])
                url = url[:at]
        except ValueError:
            pass
        self.url = geturl(url)
        self.encoding = b'UTF-8'  # Subversion is always nominal UTF-8
        try:
            with util.with_lc_ctype():
                self.transport = transport.SvnRaTransport(url=self.url)
                self.ra = self.transport.ra
                self.ctx = self.transport.client
                self.baseurl = svn.ra.get_repos_root(self.ra)
                # Module is either empty or a repository path starting with
                # a slash and not ending with a slash.
                self.module = urlreq.unquote(self.url[len(self.baseurl) :])
                self.prevmodule = None
                self.rootmodule = self.module
                self.commits = {}
                self.paths = {}
                self.uuid = svn.ra.get_uuid(self.ra)
        except svn.core.SubversionException:
            ui.traceback()
            svnversion = b'%d.%d.%d' % (
                svn.core.SVN_VER_MAJOR,
                svn.core.SVN_VER_MINOR,
                svn.core.SVN_VER_MICRO,
            )
            raise NoRepo(
                _(
                    b"%s does not look like a Subversion repository "
                    b"to libsvn version %s"
                )
                % (self.url, svnversion)
            )

        if revs:
            if len(revs) > 1:
                raise error.Abort(
                    _(
                        b'subversion source does not support '
                        b'specifying multiple revisions'
                    )
                )
            try:
                latest = int(revs[0])
            except ValueError:
                raise error.Abort(
                    _(b'svn: revision %s is not an integer') % revs[0]
                )

        trunkcfg = self.ui.config(b'convert', b'svn.trunk')
        if trunkcfg is None:
            trunkcfg = b'trunk'
        self.trunkname = trunkcfg.strip(b'/')
        self.startrev = self.ui.config(b'convert', b'svn.startrev')
        try:
            self.startrev = int(self.startrev)
            if self.startrev < 0:
                self.startrev = 0
        except ValueError:
            raise error.Abort(
                _(b'svn: start revision %s is not an integer') % self.startrev
            )

        try:
            with util.with_lc_ctype():
                self.head = self.latest(self.module, latest)
        except SvnPathNotFound:
            self.head = None
        if not self.head:
            raise error.Abort(
                _(b'no revision found in module %s') % self.module
            )
        self.last_changed = self.revnum(self.head)

        self._changescache = (None, None)

        if os.path.exists(os.path.join(url, b'.svn/entries')):
            self.wc = url
        else:
            self.wc = None
        self.convertfp = None
###END###
def before(self):
        self.with_lc_ctype = util.with_lc_ctype()
        self.with_lc_ctype.__enter__()
###END###
def after(self):
        self.with_lc_ctype.__exit__(None, None, None)
###END###
def setrevmap(self, revmap):
        lastrevs = {}
        for revid in revmap:
            uuid, module, revnum = revsplit(revid)
            lastrevnum = lastrevs.setdefault(module, revnum)
            if revnum > lastrevnum:
                lastrevs[module] = revnum
        self.lastrevs = lastrevs
###END###
def exists(self, path, optrev):
        try:
            svn.client.ls(
                self.url.rstrip(b'/') + b'/' + quote(path),
                optrev,
                False,
                self.ctx,
            )
            return True
        except svn.core.SubversionException:
            return False
###END###
def getheads(self):
        def isdir(path, revnum):
            kind = self._checkpath(path, revnum)
            return kind == svn.core.svn_node_dir

        def getcfgpath(name, rev):
            cfgpath = self.ui.config(b'convert', b'svn.' + name)
            if cfgpath is not None and cfgpath.strip() == b'':
                return None
            path = (cfgpath or name).strip(b'/')
            if not self.exists(path, rev):
                if self.module.endswith(path) and name == b'trunk':
                    # we are converting from inside this directory
                    return None
                if cfgpath:
                    raise error.Abort(
                        _(b'expected %s to be at %r, but not found')
                        % (name, path)
                    )
                return None
            self.ui.note(
                _(b'found %s at %r\n') % (name, pycompat.bytestr(path))
            )
            return path

        rev = optrev(self.last_changed)
        oldmodule = b''
        trunk = getcfgpath(b'trunk', rev)
        self.tags = getcfgpath(b'tags', rev)
        branches = getcfgpath(b'branches', rev)

        # If the project has a trunk or branches, we will extract heads
        # from them. We keep the project root otherwise.
        if trunk:
            oldmodule = self.module or b''
            self.module += b'/' + trunk
            self.head = self.latest(self.module, self.last_changed)
            if not self.head:
                raise error.Abort(
                    _(b'no revision found in module %s') % self.module
                )

        # First head in the list is the module's head
        self.heads = [self.head]
        if self.tags is not None:
            self.tags = b'%s/%s' % (oldmodule, (self.tags or b'tags'))

        # Check if branches bring a few more heads to the list
        if branches:
            rpath = self.url.strip(b'/')
            branchnames = svn.client.ls(
                rpath + b'/' + quote(branches), rev, False, self.ctx
            )
            for branch in sorted(branchnames):
                module = b'%s/%s/%s' % (oldmodule, branches, branch)
                if not isdir(module, self.last_changed):
                    continue
                brevid = self.latest(module, self.last_changed)
                if not brevid:
                    self.ui.note(_(b'ignoring empty branch %s\n') % branch)
                    continue
                self.ui.note(
                    _(b'found branch %s at %d\n')
                    % (branch, self.revnum(brevid))
                )
                self.heads.append(brevid)

        if self.startrev and self.heads:
            if len(self.heads) > 1:
                raise error.Abort(
                    _(
                        b'svn: start revision is not supported '
                        b'with more than one branch'
                    )
                )
            revnum = self.revnum(self.heads[0])
            if revnum < self.startrev:
                raise error.Abort(
                    _(b'svn: no revision found after start revision %d')
                    % self.startrev
                )

        return self.heads
###END###
def _getchanges(self, rev, full):
        (paths, parents) = self.paths[rev]
        copies = {}
        if parents:
            files, self.removed, copies = self.expandpaths(rev, paths, parents)
        if full or not parents:
            # Perform a full checkout on roots
            uuid, module, revnum = revsplit(rev)
            entries = svn.client.ls(
                self.baseurl + quote(module), optrev(revnum), True, self.ctx
            )
            files = [
                n
                for n, e in pycompat.iteritems(entries)
                if e.kind == svn.core.svn_node_file
            ]
            self.removed = set()

        files.sort()
        files = pycompat.ziplist(files, [rev] * len(files))
        return (files, copies)
###END###
def getchanges(self, rev, full):
        # reuse cache from getchangedfiles
        if self._changescache[0] == rev and not full:
            (files, copies) = self._changescache[1]
        else:
            (files, copies) = self._getchanges(rev, full)
            # caller caches the result, so free it here to release memory
            del self.paths[rev]
        return (files, copies, set())
###END###
def getchangedfiles(self, rev, i):
        # called from filemap - cache computed values for reuse in getchanges
        (files, copies) = self._getchanges(rev, False)
        self._changescache = (rev, (files, copies))
        return [f[0] for f in files]
###END###
def getcommit(self, rev):
        if rev not in self.commits:
            uuid, module, revnum = revsplit(rev)
            self.module = module
            self.reparent(module)
            # We assume that:
            # - requests for revisions after "stop" come from the
            # revision graph backward traversal. Cache all of them
            # down to stop, they will be used eventually.
            # - requests for revisions before "stop" come to get
            # isolated branches parents. Just fetch what is needed.
            stop = self.lastrevs.get(module, 0)
            if revnum < stop:
                stop = revnum + 1
            self._fetch_revisions(revnum, stop)
            if rev not in self.commits:
                raise error.Abort(_(b'svn: revision %s not found') % revnum)
        revcommit = self.commits[rev]
        # caller caches the result, so free it here to release memory
        del self.commits[rev]
        return revcommit
###END###
def checkrevformat(self, revstr, mapname=b'splicemap'):
        """fails if revision format does not match the correct format"""
        if not re.match(
            br'svn:[0-9a-f]{8,8}-[0-9a-f]{4,4}-'
            br'[0-9a-f]{4,4}-[0-9a-f]{4,4}-[0-9a-f]'
            br'{12,12}(.*)@[0-9]+$',
            revstr,
        ):
            raise error.Abort(
                _(b'%s entry %s is not a valid revision identifier')
                % (mapname, revstr)
            )
###END###
def numcommits(self):
        return int(self.head.rsplit(b'@', 1)[1]) - self.startrev
###END###
def gettags(self):
        tags = {}
        if self.tags is None:
            return tags

        # svn tags are just a convention, project branches left in a
        # 'tags' directory. There is no other relationship than
        # ancestry, which is expensive to discover and makes them hard
        # to update incrementally.  Worse, past revisions may be
        # referenced by tags far away in the future, requiring a deep
        # history traversal on every calculation.  Current code
        # performs a single backward traversal, tracking moves within
        # the tags directory (tag renaming) and recording a new tag
        # everytime a project is copied from outside the tags
        # directory. It also lists deleted tags, this behaviour may
        # change in the future.
        pendings = []
        tagspath = self.tags
        start = svn.ra.get_latest_revnum(self.ra)
        stream = self._getlog([self.tags], start, self.startrev)
        try:
            for entry in stream:
                origpaths, revnum, author, date, message = entry
                if not origpaths:
                    origpaths = []
                copies = [
                    (e.copyfrom_path, e.copyfrom_rev, p)
                    for p, e in pycompat.iteritems(origpaths)
                    if e.copyfrom_path
                ]
                # Apply moves/copies from more specific to general
                copies.sort(reverse=True)

                srctagspath = tagspath
                if copies and copies[-1][2] == tagspath:
                    # Track tags directory moves
                    srctagspath = copies.pop()[0]

                for source, sourcerev, dest in copies:
                    if not dest.startswith(tagspath + b'/'):
                        continue
                    for tag in pendings:
                        if tag[0].startswith(dest):
                            tagpath = source + tag[0][len(dest) :]
                            tag[:2] = [tagpath, sourcerev]
                            break
                    else:
                        pendings.append([source, sourcerev, dest])

                # Filter out tags with children coming from different
                # parts of the repository like:
                # /tags/tag.1 (from /trunk:10)
                # /tags/tag.1/foo (from /branches/foo:12)
                # Here/tags/tag.1 discarded as well as its children.
                # It happens with tools like cvs2svn. Such tags cannot
                # be represented in mercurial.
                addeds = {
                    p: e.copyfrom_path
                    for p, e in pycompat.iteritems(origpaths)
                    if e.action == b'A' and e.copyfrom_path
                }
                badroots = set()
                for destroot in addeds:
                    for source, sourcerev, dest in pendings:
                        if not dest.startswith(
                            destroot + b'/'
                        ) or source.startswith(addeds[destroot] + b'/'):
                            continue
                        badroots.add(destroot)
                        break

                for badroot in badroots:
                    pendings = [
                        p
                        for p in pendings
                        if p[2] != badroot
                        and not p[2].startswith(badroot + b'/')
                    ]

                # Tell tag renamings from tag creations
                renamings = []
                for source, sourcerev, dest in pendings:
                    tagname = dest.split(b'/')[-1]
                    if source.startswith(srctagspath):
                        renamings.append([source, sourcerev, tagname])
                        continue
                    if tagname in tags:
                        # Keep the latest tag value
                        continue
                    # From revision may be fake, get one with changes
                    try:
                        tagid = self.latest(source, sourcerev)
                        if tagid and tagname not in tags:
                            tags[tagname] = tagid
                    except SvnPathNotFound:
                        # It happens when we are following directories
                        # we assumed were copied with their parents
                        # but were really created in the tag
                        # directory.
                        pass
                pendings = renamings
                tagspath = srctagspath
        finally:
            stream.close()
        return tags
###END###
def converted(self, rev, destrev):
        if not self.wc:
            return
        if self.convertfp is None:
            self.convertfp = open(
                os.path.join(self.wc, b'.svn', b'hg-shamap'), b'ab'
            )
        self.convertfp.write(
            util.tonativeeol(b'%s %d\n' % (destrev, self.revnum(rev)))
        )
        self.convertfp.flush()
###END###
def revid(self, revnum, module=None):
        return b'svn:%s%s@%d' % (self.uuid, module or self.module, revnum)
###END###
def revnum(self, rev):
        return int(rev.split(b'@')[-1])
###END###
def latest(self, path, stop=None):
        """Find the latest revid affecting path, up to stop revision
        number. If stop is None, default to repository latest
        revision. It may return a revision in a different module,
        since a branch may be moved without a change being
        reported. Return None if computed module does not belong to
        rootmodule subtree.
        """

        def findchanges(path, start, stop=None):
            stream = self._getlog([path], start, stop or 1)
            try:
                for entry in stream:
                    paths, revnum, author, date, message = entry
                    if stop is None and paths:
                        # We do not know the latest changed revision,
                        # keep the first one with changed paths.
                        break
                    if stop is not None and revnum <= stop:
                        break

                    for p in paths:
                        if not path.startswith(p) or not paths[p].copyfrom_path:
                            continue
                        newpath = paths[p].copyfrom_path + path[len(p) :]
                        self.ui.debug(
                            b"branch renamed from %s to %s at %d\n"
                            % (path, newpath, revnum)
                        )
                        path = newpath
                        break
                if not paths:
                    revnum = None
                return revnum, path
            finally:
                stream.close()

        if not path.startswith(self.rootmodule):
            # Requests on foreign branches may be forbidden at server level
            self.ui.debug(b'ignoring foreign branch %r\n' % path)
            return None

        if stop is None:
            stop = svn.ra.get_latest_revnum(self.ra)
        try:
            prevmodule = self.reparent(b'')
            dirent = svn.ra.stat(self.ra, path.strip(b'/'), stop)
            self.reparent(prevmodule)
        except svn.core.SubversionException:
            dirent = None
        if not dirent:
            raise SvnPathNotFound(
                _(b'%s not found up to revision %d') % (path, stop)
            )

        # stat() gives us the previous revision on this line of
        # development, but it might be in *another module*. Fetch the
        # log and detect renames down to the latest revision.
        revnum, realpath = findchanges(path, stop, dirent.created_rev)
        if revnum is None:
            # Tools like svnsync can create empty revision, when
            # synchronizing only a subtree for instance. These empty
            # revisions created_rev still have their original values
            # despite all changes having disappeared and can be
            # returned by ra.stat(), at least when stating the root
            # module. In that case, do not trust created_rev and scan
            # the whole history.
            revnum, realpath = findchanges(path, stop)
            if revnum is None:
                self.ui.debug(b'ignoring empty branch %r\n' % realpath)
                return None

        if not realpath.startswith(self.rootmodule):
            self.ui.debug(b'ignoring foreign branch %r\n' % realpath)
            return None
        return self.revid(revnum, realpath)
###END###
def reparent(self, module):
        """Reparent the svn transport and return the previous parent."""
        if self.prevmodule == module:
            return module
        svnurl = self.baseurl + quote(module)
        prevmodule = self.prevmodule
        if prevmodule is None:
            prevmodule = b''
        self.ui.debug(b"reparent to %s\n" % svnurl)
        svn.ra.reparent(self.ra, svnurl)
        self.prevmodule = module
        return prevmodule
###END###
def expandpaths(self, rev, paths, parents):
        changed, removed = set(), set()
        copies = {}

        new_module, revnum = revsplit(rev)[1:]
        if new_module != self.module:
            self.module = new_module
            self.reparent(self.module)

        progress = self.ui.makeprogress(
            _(b'scanning paths'), unit=_(b'paths'), total=len(paths)
        )
        for i, (path, ent) in enumerate(paths):
            progress.update(i, item=path)
            entrypath = self.getrelpath(path)

            kind = self._checkpath(entrypath, revnum)
            if kind == svn.core.svn_node_file:
                changed.add(self.recode(entrypath))
                if not ent.copyfrom_path or not parents:
                    continue
                # Copy sources not in parent revisions cannot be
                # represented, ignore their origin for now
                pmodule, prevnum = revsplit(parents[0])[1:]
                if ent.copyfrom_rev < prevnum:
                    continue
                copyfrom_path = self.getrelpath(ent.copyfrom_path, pmodule)
                if not copyfrom_path:
                    continue
                self.ui.debug(
                    b"copied to %s from %s@%d\n"
                    % (entrypath, copyfrom_path, ent.copyfrom_rev)
                )
                copies[self.recode(entrypath)] = self.recode(copyfrom_path)
            elif kind == 0:  # gone, but had better be a deleted *file*
                self.ui.debug(b"gone from %d\n" % ent.copyfrom_rev)
                pmodule, prevnum = revsplit(parents[0])[1:]
                parentpath = pmodule + b"/" + entrypath
                fromkind = self._checkpath(entrypath, prevnum, pmodule)

                if fromkind == svn.core.svn_node_file:
                    removed.add(self.recode(entrypath))
                elif fromkind == svn.core.svn_node_dir:
                    oroot = parentpath.strip(b'/')
                    nroot = path.strip(b'/')
                    children = self._iterfiles(oroot, prevnum)
                    for childpath in children:
                        childpath = childpath.replace(oroot, nroot)
                        childpath = self.getrelpath(b"/" + childpath, pmodule)
                        if childpath:
                            removed.add(self.recode(childpath))
                else:
                    self.ui.debug(
                        b'unknown path in revision %d: %s\n' % (revnum, path)
                    )
            elif kind == svn.core.svn_node_dir:
                if ent.action == b'M':
                    # If the directory just had a prop change,
                    # then we shouldn't need to look for its children.
                    continue
                if ent.action == b'R' and parents:
                    # If a directory is replacing a file, mark the previous
                    # file as deleted
                    pmodule, prevnum = revsplit(parents[0])[1:]
                    pkind = self._checkpath(entrypath, prevnum, pmodule)
                    if pkind == svn.core.svn_node_file:
                        removed.add(self.recode(entrypath))
                    elif pkind == svn.core.svn_node_dir:
                        # We do not know what files were kept or removed,
                        # mark them all as changed.
                        for childpath in self._iterfiles(pmodule, prevnum):
                            childpath = self.getrelpath(b"/" + childpath)
                            if childpath:
                                changed.add(self.recode(childpath))

                for childpath in self._iterfiles(path, revnum):
                    childpath = self.getrelpath(b"/" + childpath)
                    if childpath:
                        changed.add(self.recode(childpath))

                # Handle directory copies
                if not ent.copyfrom_path or not parents:
                    continue
                # Copy sources not in parent revisions cannot be
                # represented, ignore their origin for now
                pmodule, prevnum = revsplit(parents[0])[1:]
                if ent.copyfrom_rev < prevnum:
                    continue
                copyfrompath = self.getrelpath(ent.copyfrom_path, pmodule)
                if not copyfrompath:
                    continue
                self.ui.debug(
                    b"mark %s came from %s:%d\n"
                    % (path, copyfrompath, ent.copyfrom_rev)
                )
                children = self._iterfiles(ent.copyfrom_path, ent.copyfrom_rev)
                for childpath in children:
                    childpath = self.getrelpath(b"/" + childpath, pmodule)
                    if not childpath:
                        continue
                    copytopath = path + childpath[len(copyfrompath) :]
                    copytopath = self.getrelpath(copytopath)
                    copies[self.recode(copytopath)] = self.recode(childpath)

        progress.complete()
        changed.update(removed)
        return (list(changed), removed, copies)
###END###
def _fetch_revisions(self, from_revnum, to_revnum):
        if from_revnum < to_revnum:
            from_revnum, to_revnum = to_revnum, from_revnum

        self.child_cset = None

        def parselogentry(orig_paths, revnum, author, date, message):
            """Return the parsed commit object or None, and True if
            the revision is a branch root.
            """
            self.ui.debug(
                b"parsing revision %d (%d changes)\n"
                % (revnum, len(orig_paths))
            )

            branched = False
            rev = self.revid(revnum)
            # branch log might return entries for a parent we already have

            if rev in self.commits or revnum < to_revnum:
                return None, branched

            parents = []
            # check whether this revision is the start of a branch or part
            # of a branch renaming
            orig_paths = sorted(pycompat.iteritems(orig_paths))
            root_paths = [
                (p, e) for p, e in orig_paths if self.module.startswith(p)
            ]
            if root_paths:
                path, ent = root_paths[-1]
                if ent.copyfrom_path:
                    branched = True
                    newpath = ent.copyfrom_path + self.module[len(path) :]
                    # ent.copyfrom_rev may not be the actual last revision
                    previd = self.latest(newpath, ent.copyfrom_rev)
                    if previd is not None:
                        prevmodule, prevnum = revsplit(previd)[1:]
                        if prevnum >= self.startrev:
                            parents = [previd]
                            self.ui.note(
                                _(b'found parent of branch %s at %d: %s\n')
                                % (self.module, prevnum, prevmodule)
                            )
                else:
                    self.ui.debug(b"no copyfrom path, don't know what to do.\n")

            paths = []
            # filter out unrelated paths
            for path, ent in orig_paths:
                if self.getrelpath(path) is None:
                    continue
                paths.append((path, ent))

            date = parsesvndate(date)
            if self.ui.configbool(b'convert', b'localtimezone'):
                date = makedatetimestamp(date[0])

            if message:
                log = self.recode(message)
            else:
                log = b''

            if author:
                author = self.recode(author)
            else:
                author = b''

            try:
                branch = self.module.split(b"/")[-1]
                if branch == self.trunkname:
                    branch = None
            except IndexError:
                branch = None

            cset = commit(
                author=author,
                date=dateutil.datestr(date, b'%Y-%m-%d %H:%M:%S %1%2'),
                desc=log,
                parents=parents,
                branch=branch,
                rev=rev,
            )

            self.commits[rev] = cset
            # The parents list is *shared* among self.paths and the
            # commit object. Both will be updated below.
            self.paths[rev] = (paths, cset.parents)
            if self.child_cset and not self.child_cset.parents:
                self.child_cset.parents[:] = [rev]
            self.child_cset = cset
            return cset, branched

        self.ui.note(
            _(b'fetching revision log for "%s" from %d to %d\n')
            % (self.module, from_revnum, to_revnum)
        )

        try:
            firstcset = None
            lastonbranch = False
            stream = self._getlog([self.module], from_revnum, to_revnum)
            try:
                for entry in stream:
                    paths, revnum, author, date, message = entry
                    if revnum < self.startrev:
                        lastonbranch = True
                        break
                    if not paths:
                        self.ui.debug(b'revision %d has no entries\n' % revnum)
                        # If we ever leave the loop on an empty
                        # revision, do not try to get a parent branch
                        lastonbranch = lastonbranch or revnum == 0
                        continue
                    cset, lastonbranch = parselogentry(
                        paths, revnum, author, date, message
                    )
                    if cset:
                        firstcset = cset
                    if lastonbranch:
                        break
            finally:
                stream.close()

            if not lastonbranch and firstcset and not firstcset.parents:
                # The first revision of the sequence (the last fetched one)
                # has invalid parents if not a branch root. Find the parent
                # revision now, if any.
                try:
                    firstrevnum = self.revnum(firstcset.rev)
                    if firstrevnum > 1:
                        latest = self.latest(self.module, firstrevnum - 1)
                        if latest:
                            firstcset.parents.append(latest)
                except SvnPathNotFound:
                    pass
        except svn.core.SubversionException as xxx_todo_changeme:
            (inst, num) = xxx_todo_changeme.args
            if num == svn.core.SVN_ERR_FS_NO_SUCH_REVISION:
                raise error.Abort(
                    _(b'svn: branch has no revision %s') % to_revnum
                )
            raise
###END###
def getfile(self, file, rev):
        # TODO: ra.get_file transmits the whole file instead of diffs.
        if file in self.removed:
            return None, None
        try:
            new_module, revnum = revsplit(rev)[1:]
            if self.module != new_module:
                self.module = new_module
                self.reparent(self.module)
            io = stringio()
            info = svn.ra.get_file(self.ra, file, revnum, io)
            data = io.getvalue()
            # ra.get_file() seems to keep a reference on the input buffer
            # preventing collection. Release it explicitly.
            io.close()
            if isinstance(info, list):
                info = info[-1]
            mode = (b"svn:executable" in info) and b'x' or b''
            mode = (b"svn:special" in info) and b'l' or mode
        except svn.core.SubversionException as e:
            notfound = (
                svn.core.SVN_ERR_FS_NOT_FOUND,
                svn.core.SVN_ERR_RA_DAV_PATH_NOT_FOUND,
            )
            if e.apr_err in notfound:  # File not found
                return None, None
            raise
        if mode == b'l':
            link_prefix = b"link "
            if data.startswith(link_prefix):
                data = data[len(link_prefix) :]
        return data, mode
###END###
def _iterfiles(self, path, revnum):
        """Enumerate all files in path at revnum, recursively."""
        path = path.strip(b'/')
        pool = svn.core.Pool()
        rpath = b'/'.join([self.baseurl, quote(path)]).strip(b'/')
        entries = svn.client.ls(rpath, optrev(revnum), True, self.ctx, pool)
        if path:
            path += b'/'
        return (
            (path + p)
            for p, e in pycompat.iteritems(entries)
            if e.kind == svn.core.svn_node_file
        )
###END###
def getrelpath(self, path, module=None):
        if module is None:
            module = self.module
        # Given the repository url of this wc, say
        #   "http://server/plone/CMFPlone/branches/Plone-2_0-branch"
        # extract the "entry" portion (a relative path) from what
        # svn log --xml says, i.e.
        #   "/CMFPlone/branches/Plone-2_0-branch/tests/PloneTestCase.py"
        # that is to say "tests/PloneTestCase.py"
        if path.startswith(module):
            relative = path.rstrip(b'/')[len(module) :]
            if relative.startswith(b'/'):
                return relative[1:]
            elif relative == b'':
                return relative

        # The path is outside our tracked tree...
        self.ui.debug(
            b'%r is not under %r, ignoring\n'
            % (pycompat.bytestr(path), pycompat.bytestr(module))
        )
        return None
###END###
def _checkpath(self, path, revnum, module=None):
        if module is not None:
            prevmodule = self.reparent(b'')
            path = module + b'/' + path
        try:
            # ra.check_path does not like leading slashes very much, it leads
            # to PROPFIND subversion errors
            return svn.ra.check_path(self.ra, path.strip(b'/'), revnum)
        finally:
            if module is not None:
                self.reparent(prevmodule)
###END###
def _getlog(
        self,
        paths,
        start,
        end,
        limit=0,
        discover_changed_paths=True,
        strict_node_history=False,
    ):
        # Normalize path names, svn >= 1.5 only wants paths relative to
        # supplied URL
        relpaths = []
        for p in paths:
            if not p.startswith(b'/'):
                p = self.module + b'/' + p
            relpaths.append(p.strip(b'/'))
        args = [
            self.baseurl,
            relpaths,
            start,
            end,
            limit,
            discover_changed_paths,
            strict_node_history,
        ]
        # developer config: convert.svn.debugsvnlog
        if not self.ui.configbool(b'convert', b'svn.debugsvnlog'):
            return directlogstream(*args)
        arg = encodeargs(args)
        hgexe = procutil.hgexecutable()
        cmd = b'%s debugsvnlog' % procutil.shellquote(hgexe)
        stdin, stdout = procutil.popen2(cmd)
        stdin.write(arg)
        try:
            stdin.close()
        except IOError:
            raise error.Abort(
                _(
                    b'Mercurial failed to run itself, check'
                    b' hg executable is in PATH'
                )
            )
        return logstream(stdout)
###END###
def prerun(self):
        if self.wc:
            os.chdir(self.wc)
###END###
def postrun(self):
        if self.wc:
            os.chdir(self.cwd)
###END###
def join(self, name):
        return os.path.join(self.wc, b'.svn', name)
###END###
def revmapfile(self):
        return self.join(b'hg-shamap')
###END###
def authorfile(self):
        return self.join(b'hg-authormap')
###END###
def __init__(self, ui, repotype, path):

        converter_sink.__init__(self, ui, repotype, path)
        commandline.__init__(self, ui, b'svn')
        self.delete = []
        self.setexec = []
        self.delexec = []
        self.copies = []
        self.wc = None
        self.cwd = encoding.getcwd()

        created = False
        if os.path.isfile(os.path.join(path, b'.svn', b'entries')):
            self.wc = os.path.realpath(path)
            self.run0(b'update')
        else:
            if not re.search(br'^(file|http|https|svn|svn\+ssh)://', path):
                path = os.path.realpath(path)
                if os.path.isdir(os.path.dirname(path)):
                    if not os.path.exists(
                        os.path.join(path, b'db', b'fs-type')
                    ):
                        ui.status(
                            _(b"initializing svn repository '%s'\n")
                            % os.path.basename(path)
                        )
                        commandline(ui, b'svnadmin').run0(b'create', path)
                        created = path
                    path = util.normpath(path)
                    if not path.startswith(b'/'):
                        path = b'/' + path
                    path = b'file://' + path

            wcpath = os.path.join(
                encoding.getcwd(), os.path.basename(path) + b'-wc'
            )
            ui.status(
                _(b"initializing svn working copy '%s'\n")
                % os.path.basename(wcpath)
            )
            self.run0(b'checkout', path, wcpath)

            self.wc = wcpath
        self.opener = vfsmod.vfs(self.wc)
        self.wopener = vfsmod.vfs(self.wc)
        self.childmap = mapfile(ui, self.join(b'hg-childmap'))
        if util.checkexec(self.wc):
            self.is_exec = util.isexec
        else:
            self.is_exec = None

        if created:
            prop_actions_allowed = [
                (b'M', b'svn:log'),
                (b'A', b'hg:convert-branch'),
                (b'A', b'hg:convert-rev'),
            ]

            if self.ui.configbool(
                b'convert', b'svn.dangerous-set-commit-dates'
            ):
                prop_actions_allowed.append((b'M', b'svn:date'))

            hook = os.path.join(created, b'hooks', b'pre-revprop-change')
            fp = open(hook, b'wb')
            fp.write(gen_pre_revprop_change_hook(prop_actions_allowed))
            fp.close()
            util.setflags(hook, False, True)

        output = self.run0(b'info')
        self.uuid = self.uuid_re.search(output).group(1).strip()
###END###
def wjoin(self, *names):
        return os.path.join(self.wc, *names)
###END###
def manifest(self):
        # As of svn 1.7, the "add" command fails when receiving
        # already tracked entries, so we have to track and filter them
        # ourselves.
        m = set()
        output = self.run0(b'ls', recursive=True, xml=True)
        doc = xml.dom.minidom.parseString(output)
        for e in doc.getElementsByTagName('entry'):
            for n in e.childNodes:
                if n.nodeType != n.ELEMENT_NODE or n.tagName != 'name':
                    continue
                name = ''.join(
                    c.data for c in n.childNodes if c.nodeType == c.TEXT_NODE
                )
                # Entries are compared with names coming from
                # mercurial, so bytes with undefined encoding. Our
                # best bet is to assume they are in local
                # encoding. They will be passed to command line calls
                # later anyway, so they better be.
                m.add(encoding.unitolocal(name))
                break
        return m
###END###
def putfile(self, filename, flags, data):
        if b'l' in flags:
            self.wopener.symlink(data, filename)
        else:
            try:
                if os.path.islink(self.wjoin(filename)):
                    os.unlink(filename)
            except OSError:
                pass

            if self.is_exec:
                # We need to check executability of the file before the change,
                # because `vfs.write` is able to reset exec bit.
                wasexec = False
                if os.path.exists(self.wjoin(filename)):
                    wasexec = self.is_exec(self.wjoin(filename))

            self.wopener.write(filename, data)

            if self.is_exec:
                if wasexec:
                    if b'x' not in flags:
                        self.delexec.append(filename)
                else:
                    if b'x' in flags:
                        self.setexec.append(filename)
                util.setflags(self.wjoin(filename), False, b'x' in flags)
###END###
def _copyfile(self, source, dest):
        # SVN's copy command pukes if the destination file exists, but
        # our copyfile method expects to record a copy that has
        # already occurred.  Cross the semantic gap.
        wdest = self.wjoin(dest)
        exists = os.path.lexists(wdest)
        if exists:
            fd, tempname = pycompat.mkstemp(
                prefix=b'hg-copy-', dir=os.path.dirname(wdest)
            )
            os.close(fd)
            os.unlink(tempname)
            os.rename(wdest, tempname)
        try:
            self.run0(b'copy', source, dest)
        finally:
            self.manifest.add(dest)
            if exists:
                try:
                    os.unlink(wdest)
                except OSError:
                    pass
                os.rename(tempname, wdest)
###END###
def dirs_of(self, files):
        dirs = set()
        for f in files:
            if os.path.isdir(self.wjoin(f)):
                dirs.add(f)
            i = len(f)
            for i in iter(lambda: f.rfind(b'/', 0, i), -1):
                dirs.add(f[:i])
        return dirs
###END###
def add_dirs(self, files):
        add_dirs = [
            d for d in sorted(self.dirs_of(files)) if d not in self.manifest
        ]
        if add_dirs:
            self.manifest.update(add_dirs)
            self.xargs(add_dirs, b'add', non_recursive=True, quiet=True)
        return add_dirs
###END###
def add_files(self, files):
        files = [f for f in files if f not in self.manifest]
        if files:
            self.manifest.update(files)
            self.xargs(files, b'add', quiet=True)
        return files
###END###
def addchild(self, parent, child):
        self.childmap[parent] = child
###END###
def revid(self, rev):
        return b"svn:%s@%s" % (self.uuid, rev)
###END###
def putcommit(
        self, files, copies, parents, commit, source, revmap, full, cleanp2
    ):
        for parent in parents:
            try:
                return self.revid(self.childmap[parent])
            except KeyError:
                pass

        # Apply changes to working copy
        for f, v in files:
            data, mode = source.getfile(f, v)
            if data is None:
                self.delete.append(f)
            else:
                self.putfile(f, mode, data)
                if f in copies:
                    self.copies.append([copies[f], f])
        if full:
            self.delete.extend(sorted(self.manifest.difference(files)))
        files = [f[0] for f in files]

        entries = set(self.delete)
        files = frozenset(files)
        entries.update(self.add_dirs(files.difference(entries)))
        if self.copies:
            for s, d in self.copies:
                self._copyfile(s, d)
            self.copies = []
        if self.delete:
            self.xargs(self.delete, b'delete')
            for f in self.delete:
                self.manifest.remove(f)
            self.delete = []
        entries.update(self.add_files(files.difference(entries)))
        if self.delexec:
            self.xargs(self.delexec, b'propdel', b'svn:executable')
            self.delexec = []
        if self.setexec:
            self.xargs(self.setexec, b'propset', b'svn:executable', b'*')
            self.setexec = []

        fd, messagefile = pycompat.mkstemp(prefix=b'hg-convert-')
        fp = os.fdopen(fd, 'wb')
        fp.write(util.tonativeeol(commit.desc))
        fp.close()
        try:
            output = self.run0(
                b'commit',
                username=stringutil.shortuser(commit.author),
                file=messagefile,
                encoding=b'utf-8',
            )
            try:
                rev = self.commit_re.search(output).group(1)
            except AttributeError:
                if not files:
                    return parents[0] if parents else b'None'
                self.ui.warn(_(b'unexpected svn output:\n'))
                self.ui.warn(output)
                raise error.Abort(_(b'unable to cope with svn output'))
            if commit.rev:
                self.run(
                    b'propset',
                    b'hg:convert-rev',
                    commit.rev,
                    revprop=True,
                    revision=rev,
                )
            if commit.branch and commit.branch != b'default':
                self.run(
                    b'propset',
                    b'hg:convert-branch',
                    commit.branch,
                    revprop=True,
                    revision=rev,
                )

            if self.ui.configbool(
                b'convert', b'svn.dangerous-set-commit-dates'
            ):
                # Subverson always uses UTC to represent date and time
                date = dateutil.parsedate(commit.date)
                date = (date[0], 0)

                # The only way to set date and time for svn commit is to use propset after commit is done
                self.run(
                    b'propset',
                    b'svn:date',
                    formatsvndate(date),
                    revprop=True,
                    revision=rev,
                )

            for parent in parents:
                self.addchild(parent, rev)
            return self.revid(rev)
        finally:
            os.unlink(messagefile)
###END###
def puttags(self, tags):
        self.ui.warn(_(b'writing Subversion tags is not yet implemented\n'))
        return None, None
###END###
def hascommitfrommap(self, rev):
        # We trust that revisions referenced in a map still is present
        # TODO: implement something better if necessary and feasible
        return True
###END###
def hascommitforsplicemap(self, rev):
        # This is not correct as one can convert to an existing subversion
        # repository and childmap would not list all revisions. Too bad.
        if rev in self.childmap:
            return True
        raise error.Abort(
            _(
                b'splice map revision %s not found in subversion '
                b'child map (revision lookups are not implemented)'
            )
            % rev
        )
###END###
def __init__(self, ui, repotype, path):
        common.converter_sink.__init__(self, ui, repotype, path)
        self.branchnames = ui.configbool(b'convert', b'hg.usebranchnames')
        self.clonebranches = ui.configbool(b'convert', b'hg.clonebranches')
        self.tagsbranch = ui.config(b'convert', b'hg.tagsbranch')
        self.lastbranch = None
        if os.path.isdir(path) and len(os.listdir(path)) > 0:
            try:
                self.repo = hg.repository(self.ui, path)
                if not self.repo.local():
                    raise NoRepo(
                        _(b'%s is not a local Mercurial repository') % path
                    )
            except error.RepoError as err:
                ui.traceback()
                raise NoRepo(err.args[0])
        else:
            try:
                ui.status(_(b'initializing destination %s repository\n') % path)
                self.repo = hg.repository(self.ui, path, create=True)
                if not self.repo.local():
                    raise NoRepo(
                        _(b'%s is not a local Mercurial repository') % path
                    )
                self.created.append(path)
            except error.RepoError:
                ui.traceback()
                raise NoRepo(
                    _(b"could not create hg repository %s as sink") % path
                )
        self.lock = None
        self.wlock = None
        self.filemapmode = False
        self.subrevmaps = {}
###END###
def before(self):
        self.ui.debug(b'run hg sink pre-conversion action\n')
        self.wlock = self.repo.wlock()
        self.lock = self.repo.lock()
###END###
def after(self):
        self.ui.debug(b'run hg sink post-conversion action\n')
        if self.lock:
            self.lock.release()
        if self.wlock:
            self.wlock.release()
###END###
def revmapfile(self):
        return self.repo.vfs.join(b"shamap")
###END###
def authorfile(self):
        return self.repo.vfs.join(b"authormap")
###END###
def setbranch(self, branch, pbranches):
        if not self.clonebranches:
            return

        setbranch = branch != self.lastbranch
        self.lastbranch = branch
        if not branch:
            branch = b'default'
        pbranches = [(b[0], b[1] and b[1] or b'default') for b in pbranches]

        branchpath = os.path.join(self.path, branch)
        if setbranch:
            self.after()
            try:
                self.repo = hg.repository(self.ui, branchpath)
            except Exception:
                self.repo = hg.repository(self.ui, branchpath, create=True)
            self.before()

        # pbranches may bring revisions from other branches (merge parents)
        # Make sure we have them, or pull them.
        missings = {}
        for b in pbranches:
            try:
                self.repo.lookup(b[0])
            except Exception:
                missings.setdefault(b[1], []).append(b[0])

        if missings:
            self.after()
            for pbranch, heads in sorted(pycompat.iteritems(missings)):
                pbranchpath = os.path.join(self.path, pbranch)
                prepo = hg.peer(self.ui, {}, pbranchpath)
                self.ui.note(
                    _(b'pulling from %s into %s\n') % (pbranch, branch)
                )
                exchange.pull(
                    self.repo, prepo, [prepo.lookup(h) for h in heads]
                )
            self.before()
###END###
def _rewritetags(self, source, revmap, data):
        fp = stringio()
        for line in data.splitlines():
            s = line.split(b' ', 1)
            if len(s) != 2:
                self.ui.warn(_(b'invalid tag entry: "%s"\n') % line)
                fp.write(b'%s\n' % line)  # Bogus, but keep for hash stability
                continue
            revid = revmap.get(source.lookuprev(s[0]))
            if not revid:
                if s[0] == sha1nodeconstants.nullhex:
                    revid = s[0]
                else:
                    # missing, but keep for hash stability
                    self.ui.warn(_(b'missing tag entry: "%s"\n') % line)
                    fp.write(b'%s\n' % line)
                    continue
            fp.write(b'%s %s\n' % (revid, s[1]))
        return fp.getvalue()
###END###
def _rewritesubstate(self, source, data):
        fp = stringio()
        for line in data.splitlines():
            s = line.split(b' ', 1)
            if len(s) != 2:
                continue

            revid = s[0]
            subpath = s[1]
            if revid != sha1nodeconstants.nullhex:
                revmap = self.subrevmaps.get(subpath)
                if revmap is None:
                    revmap = mapfile(
                        self.ui, self.repo.wjoin(subpath, b'.hg/shamap')
                    )
                    self.subrevmaps[subpath] = revmap

                    # It is reasonable that one or more of the subrepos don't
                    # need to be converted, in which case they can be cloned
                    # into place instead of converted.  Therefore, only warn
                    # once.
                    msg = _(b'no ".hgsubstate" updates will be made for "%s"\n')
                    if len(revmap) == 0:
                        sub = self.repo.wvfs.reljoin(subpath, b'.hg')

                        if self.repo.wvfs.exists(sub):
                            self.ui.warn(msg % subpath)

                newid = revmap.get(revid)
                if not newid:
                    if len(revmap) > 0:
                        self.ui.warn(
                            _(b"%s is missing from %s/.hg/shamap\n")
                            % (revid, subpath)
                        )
                else:
                    revid = newid

            fp.write(b'%s %s\n' % (revid, subpath))

        return fp.getvalue()
###END###
def _calculatemergedfiles(self, source, p1ctx, p2ctx):
        """Calculates the files from p2 that we need to pull in when merging p1
        and p2, given that the merge is coming from the given source.

        This prevents us from losing files that only exist in the target p2 and
        that don't come from the source repo (like if you're merging multiple
        repositories together).
        """
        anc = [p1ctx.ancestor(p2ctx)]
        # Calculate what files are coming from p2
        # TODO: mresult.commitinfo might be able to get that info
        mresult = mergemod.calculateupdates(
            self.repo,
            p1ctx,
            p2ctx,
            anc,
            branchmerge=True,
            force=True,
            acceptremote=False,
            followcopies=False,
        )

        for file, (action, info, msg) in mresult.filemap():
            if source.targetfilebelongstosource(file):
                # If the file belongs to the source repo, ignore the p2
                # since it will be covered by the existing fileset.
                continue

            # If the file requires actual merging, abort. We don't have enough
            # context to resolve merges correctly.
            if action in [b'm', b'dm', b'cd', b'dc']:
                raise error.Abort(
                    _(
                        b"unable to convert merge commit "
                        b"since target parents do not merge cleanly (file "
                        b"%s, parents %s and %s)"
                    )
                    % (file, p1ctx, p2ctx)
                )
            elif action == b'k':
                # 'keep' means nothing changed from p1
                continue
            else:
                # Any other change means we want to take the p2 version
                yield file
###END###
def putcommit(
        self, files, copies, parents, commit, source, revmap, full, cleanp2
    ):
        files = dict(files)

        def getfilectx(repo, memctx, f):
            if p2ctx and f in p2files and f not in copies:
                self.ui.debug(b'reusing %s from p2\n' % f)
                try:
                    return p2ctx[f]
                except error.ManifestLookupError:
                    # If the file doesn't exist in p2, then we're syncing a
                    # delete, so just return None.
                    return None
            try:
                v = files[f]
            except KeyError:
                return None
            data, mode = source.getfile(f, v)
            if data is None:
                return None
            if f == b'.hgtags':
                data = self._rewritetags(source, revmap, data)
            if f == b'.hgsubstate':
                data = self._rewritesubstate(source, data)
            return context.memfilectx(
                self.repo,
                memctx,
                f,
                data,
                b'l' in mode,
                b'x' in mode,
                copies.get(f),
            )

        pl = []
        for p in parents:
            if p not in pl:
                pl.append(p)
        parents = pl
        nparents = len(parents)
        if self.filemapmode and nparents == 1:
            m1node = self.repo.changelog.read(bin(parents[0]))[0]
            parent = parents[0]

        if len(parents) < 2:
            parents.append(self.repo.nullid)
        if len(parents) < 2:
            parents.append(self.repo.nullid)
        p2 = parents.pop(0)

        text = commit.desc

        sha1s = re.findall(sha1re, text)
        for sha1 in sha1s:
            oldrev = source.lookuprev(sha1)
            newrev = revmap.get(oldrev)
            if newrev is not None:
                text = text.replace(sha1, newrev[: len(sha1)])

        extra = commit.extra.copy()

        sourcename = self.repo.ui.config(b'convert', b'hg.sourcename')
        if sourcename:
            extra[b'convert_source'] = sourcename

        for label in (
            b'source',
            b'transplant_source',
            b'rebase_source',
            b'intermediate-source',
        ):
            node = extra.get(label)

            if node is None:
                continue

            # Only transplant stores its reference in binary
            if label == b'transplant_source':
                node = hex(node)

            newrev = revmap.get(node)
            if newrev is not None:
                if label == b'transplant_source':
                    newrev = bin(newrev)

                extra[label] = newrev

        if self.branchnames and commit.branch:
            extra[b'branch'] = commit.branch
        if commit.rev and commit.saverev:
            extra[b'convert_revision'] = commit.rev

        while parents:
            p1 = p2
            p2 = parents.pop(0)
            p1ctx = self.repo[p1]
            p2ctx = None
            if p2 != self.repo.nullid:
                p2ctx = self.repo[p2]
            fileset = set(files)
            if full:
                fileset.update(self.repo[p1])
                fileset.update(self.repo[p2])

            if p2ctx:
                p2files = set(cleanp2)
                for file in self._calculatemergedfiles(source, p1ctx, p2ctx):
                    p2files.add(file)
                    fileset.add(file)

            ctx = context.memctx(
                self.repo,
                (p1, p2),
                text,
                fileset,
                getfilectx,
                commit.author,
                commit.date,
                extra,
            )

            # We won't know if the conversion changes the node until after the
            # commit, so copy the source's phase for now.
            self.repo.ui.setconfig(
                b'phases',
                b'new-commit',
                phases.phasenames[commit.phase],
                b'convert',
            )

            with self.repo.transaction(b"convert") as tr:
                if self.repo.ui.config(b'convert', b'hg.preserve-hash'):
                    origctx = commit.ctx
                else:
                    origctx = None
                node = hex(self.repo.commitctx(ctx, origctx=origctx))

                # If the node value has changed, but the phase is lower than
                # draft, set it back to draft since it hasn't been exposed
                # anywhere.
                if commit.rev != node:
                    ctx = self.repo[node]
                    if ctx.phase() < phases.draft:
                        phases.registernew(
                            self.repo, tr, phases.draft, [ctx.rev()]
                        )

            text = b"(octopus merge fixup)\n"
            p2 = node

        if self.filemapmode and nparents == 1:
            man = self.repo.manifestlog.getstorage(b'')
            mnode = self.repo.changelog.read(bin(p2))[0]
            closed = b'close' in commit.extra
            if not closed and not man.cmp(m1node, man.revision(mnode)):
                self.ui.status(_(b"filtering out empty revision\n"))
                self.repo.rollback(force=True)
                return parent
        return p2
###END###
def puttags(self, tags):
        tagparent = self.repo.branchtip(self.tagsbranch, ignoremissing=True)
        tagparent = tagparent or self.repo.nullid

        oldlines = set()
        for branch, heads in pycompat.iteritems(self.repo.branchmap()):
            for h in heads:
                if b'.hgtags' in self.repo[h]:
                    oldlines.update(
                        set(self.repo[h][b'.hgtags'].data().splitlines(True))
                    )
        oldlines = sorted(list(oldlines))

        newlines = sorted([(b"%s %s\n" % (tags[tag], tag)) for tag in tags])
        if newlines == oldlines:
            return None, None

        # if the old and new tags match, then there is nothing to update
        oldtags = set()
        newtags = set()
        for line in oldlines:
            s = line.strip().split(b' ', 1)
            if len(s) != 2:
                continue
            oldtags.add(s[1])
        for line in newlines:
            s = line.strip().split(b' ', 1)
            if len(s) != 2:
                continue
            if s[1] not in oldtags:
                newtags.add(s[1].strip())

        if not newtags:
            return None, None

        data = b"".join(newlines)

        def getfilectx(repo, memctx, f):
            return context.memfilectx(repo, memctx, f, data, False, False, None)

        self.ui.status(_(b"updating tags\n"))
        date = b"%d 0" % int(time.mktime(time.gmtime()))
        extra = {b'branch': self.tagsbranch}
        ctx = context.memctx(
            self.repo,
            (tagparent, None),
            b"update tags",
            [b".hgtags"],
            getfilectx,
            b"convert-repo",
            date,
            extra,
        )
        node = self.repo.commitctx(ctx)
        return hex(node), hex(tagparent)
###END###
def setfilemapmode(self, active):
        self.filemapmode = active
###END###
def putbookmarks(self, updatedbookmark):
        if not len(updatedbookmark):
            return
        wlock = lock = tr = None
        try:
            wlock = self.repo.wlock()
            lock = self.repo.lock()
            tr = self.repo.transaction(b'bookmark')
            self.ui.status(_(b"updating bookmarks\n"))
            destmarks = self.repo._bookmarks
            changes = [
                (bookmark, bin(updatedbookmark[bookmark]))
                for bookmark in updatedbookmark
            ]
            destmarks.applychanges(self.repo, tr, changes)
            tr.close()
        finally:
            lockmod.release(lock, wlock, tr)
###END###
def hascommitfrommap(self, rev):
        # the exact semantics of clonebranches is unclear so we can't say no
        return rev in self.repo or self.clonebranches
###END###
def hascommitforsplicemap(self, rev):
        if rev not in self.repo and self.clonebranches:
            raise error.Abort(
                _(
                    b'revision %s not found in destination '
                    b'repository (lookups with clonebranches=true '
                    b'are not implemented)'
                )
                % rev
            )
        return rev in self.repo
###END###
def __init__(self, ui, repotype, path, revs=None):
        common.converter_source.__init__(self, ui, repotype, path, revs)
        self.ignoreerrors = ui.configbool(b'convert', b'hg.ignoreerrors')
        self.ignored = set()
        self.saverev = ui.configbool(b'convert', b'hg.saverev')
        try:
            self.repo = hg.repository(self.ui, path)
            # try to provoke an exception if this isn't really a hg
            # repo, but some other bogus compatible-looking url
            if not self.repo.local():
                raise error.RepoError
        except error.RepoError:
            ui.traceback()
            raise NoRepo(_(b"%s is not a local Mercurial repository") % path)
        self.lastrev = None
        self.lastctx = None
        self._changescache = None, None
        self.convertfp = None
        # Restrict converted revisions to startrev descendants
        startnode = ui.config(b'convert', b'hg.startrev')
        hgrevs = ui.config(b'convert', b'hg.revs')
        if hgrevs is None:
            if startnode is not None:
                try:
                    startnode = self.repo.lookup(startnode)
                except error.RepoError:
                    raise error.Abort(
                        _(b'%s is not a valid start revision') % startnode
                    )
                startrev = self.repo.changelog.rev(startnode)
                children = {startnode: 1}
                for r in self.repo.changelog.descendants([startrev]):
                    children[self.repo.changelog.node(r)] = 1
                self.keep = children.__contains__
            else:
                self.keep = util.always
            if revs:
                self._heads = [self.repo.lookup(r) for r in revs]
            else:
                self._heads = self.repo.heads()
        else:
            if revs or startnode is not None:
                raise error.Abort(
                    _(
                        b'hg.revs cannot be combined with '
                        b'hg.startrev or --rev'
                    )
                )
            nodes = set()
            parents = set()
            for r in scmutil.revrange(self.repo, [hgrevs]):
                ctx = self.repo[r]
                nodes.add(ctx.node())
                parents.update(p.node() for p in ctx.parents())
            self.keep = nodes.__contains__
            self._heads = nodes - parents
###END###
def _changectx(self, rev):
        if self.lastrev != rev:
            self.lastctx = self.repo[rev]
            self.lastrev = rev
        return self.lastctx
###END###
def _parents(self, ctx):
        return [p for p in ctx.parents() if p and self.keep(p.node())]
###END###
def getheads(self):
        return [hex(h) for h in self._heads if self.keep(h)]
###END###
def getfile(self, name, rev):
        try:
            fctx = self._changectx(rev)[name]
            return fctx.data(), fctx.flags()
        except error.LookupError:
            return None, None
###END###
def _changedfiles(self, ctx1, ctx2):
        ma, r = [], []
        maappend = ma.append
        rappend = r.append
        d = ctx1.manifest().diff(ctx2.manifest())
        for f, ((node1, flag1), (node2, flag2)) in pycompat.iteritems(d):
            if node2 is None:
                rappend(f)
            else:
                maappend(f)
        return ma, r
###END###
def getchanges(self, rev, full):
        ctx = self._changectx(rev)
        parents = self._parents(ctx)
        if full or not parents:
            files = copyfiles = ctx.manifest()
        if parents:
            if self._changescache[0] == rev:
                ma, r = self._changescache[1]
            else:
                ma, r = self._changedfiles(parents[0], ctx)
            if not full:
                files = ma + r
            copyfiles = ma
        # _getcopies() is also run for roots and before filtering so missing
        # revlogs are detected early
        copies = self._getcopies(ctx, parents, copyfiles)
        cleanp2 = set()
        if len(parents) == 2:
            d = parents[1].manifest().diff(ctx.manifest(), clean=True)
            for f, value in pycompat.iteritems(d):
                if value is None:
                    cleanp2.add(f)
        changes = [(f, rev) for f in files if f not in self.ignored]
        changes.sort()
        return changes, copies, cleanp2
###END###
def _getcopies(self, ctx, parents, files):
        copies = {}
        for name in files:
            if name in self.ignored:
                continue
            try:
                copysource = ctx.filectx(name).copysource()
                if copysource in self.ignored:
                    continue
                # Ignore copy sources not in parent revisions
                if not any(copysource in p for p in parents):
                    continue
                copies[name] = copysource
            except TypeError:
                pass
            except error.LookupError as e:
                if not self.ignoreerrors:
                    raise
                self.ignored.add(name)
                self.ui.warn(_(b'ignoring: %s\n') % e)
        return copies
###END###
def getcommit(self, rev):
        ctx = self._changectx(rev)
        _parents = self._parents(ctx)
        parents = [p.hex() for p in _parents]
        optparents = [p.hex() for p in ctx.parents() if p and p not in _parents]
        crev = rev

        return common.commit(
            author=ctx.user(),
            date=dateutil.datestr(ctx.date(), b'%Y-%m-%d %H:%M:%S %1%2'),
            desc=ctx.description(),
            rev=crev,
            parents=parents,
            optparents=optparents,
            branch=ctx.branch(),
            extra=ctx.extra(),
            sortkey=ctx.rev(),
            saverev=self.saverev,
            phase=ctx.phase(),
            ctx=ctx,
        )
###END###
def numcommits(self):
        return len(self.repo)
###END###
def gettags(self):
        # This will get written to .hgtags, filter non global tags out.
        tags = [
            t
            for t in self.repo.tagslist()
            if self.repo.tagtype(t[0]) == b'global'
        ]
        return {name: hex(node) for name, node in tags if self.keep(node)}
###END###
def getchangedfiles(self, rev, i):
        ctx = self._changectx(rev)
        parents = self._parents(ctx)
        if not parents and i is None:
            i = 0
            ma, r = ctx.manifest().keys(), []
        else:
            i = i or 0
            ma, r = self._changedfiles(parents[i], ctx)
        ma, r = [[f for f in l if f not in self.ignored] for l in (ma, r)]

        if i == 0:
            self._changescache = (rev, (ma, r))

        return ma + r
###END###
def converted(self, rev, destrev):
        if self.convertfp is None:
            self.convertfp = open(self.repo.vfs.join(b'shamap'), b'ab')
        self.convertfp.write(util.tonativeeol(b'%s %s\n' % (destrev, rev)))
        self.convertfp.flush()
###END###
def before(self):
        self.ui.debug(b'run hg source pre-conversion action\n')
###END###
def after(self):
        self.ui.debug(b'run hg source post-conversion action\n')
###END###
def hasnativeorder(self):
        return True
###END###
def hasnativeclose(self):
        return True
###END###
def lookuprev(self, rev):
        try:
            return hex(self.repo.lookup(rev))
        except (error.RepoError, error.LookupError):
            return None
###END###
def getbookmarks(self):
        return bookmarks.listbookmarks(self.repo)
###END###
def checkrevformat(self, revstr, mapname=b'splicemap'):
        """Mercurial, revision string is a 40 byte hex"""
        self.checkhexformat(revstr, mapname)
###END###
def __init__(self, l):
        self._l = l
###END###
def __iter__(self):
        return (_encodeornone(v) for v in self._l)
###END###
def get_token(self):
        return _encodeornone(self._l.get_token())
###END###
def infile(self):
        return self._l.infile or b'<unknown>'
###END###
def lineno(self):
        return self._l.lineno
###END###
def __init__(
        self,
        author,
        date,
        desc,
        parents,
        branch=None,
        rev=None,
        extra=None,
        sortkey=None,
        saverev=True,
        phase=phases.draft,
        optparents=None,
        ctx=None,
    ):
        self.author = author or b'unknown'
        self.date = date or b'0 0'
        self.desc = desc
        self.parents = parents  # will be converted and used as parents
        self.optparents = optparents or []  # will be used if already converted
        self.branch = branch
        self.rev = rev
        self.extra = extra or {}
        self.sortkey = sortkey
        self.saverev = saverev
        self.phase = phase
        self.ctx = ctx
###END###
def __init__(self, ui, repotype, path=None, revs=None):
        """Initialize conversion source (or raise NoRepo("message")
        exception if path is not a valid repository)"""
        self.ui = ui
        self.path = path
        self.revs = revs
        self.repotype = repotype

        self.encoding = b'utf-8'
###END###
def checkhexformat(self, revstr, mapname=b'splicemap'):
        """fails if revstr is not a 40 byte hex. mercurial and git both uses
        such format for their revision numbering
        """
        if not re.match(br'[0-9a-fA-F]{40,40}$', revstr):
            raise error.Abort(
                _(b'%s entry %s is not a valid revision identifier')
                % (mapname, revstr)
            )
###END###
def before(self):
        pass
###END###
def after(self):
        pass
###END###
def targetfilebelongstosource(self, targetfilename):
        """Returns true if the given targetfile belongs to the source repo. This
        is useful when only a subdirectory of the target belongs to the source
        repo."""
        # For normal full repo converts, this is always True.
        return True
###END###
def setrevmap(self, revmap):
        """set the map of already-converted revisions"""
###END###
def getheads(self):
        """Return a list of this repository's heads"""
        raise NotImplementedError
###END###
def getfile(self, name, rev):
        """Return a pair (data, mode) where data is the file content
        as a string and mode one of '', 'x' or 'l'. rev is the
        identifier returned by a previous call to getchanges().
        Data is None if file is missing/deleted in rev.
        """
        raise NotImplementedError
###END###
def getchanges(self, version, full):
        """Returns a tuple of (files, copies, cleanp2).

        files is a sorted list of (filename, id) tuples for all files
        changed between version and its first parent returned by
        getcommit(). If full, all files in that revision is returned.
        id is the source revision id of the file.

        copies is a dictionary of dest: source

        cleanp2 is the set of files filenames that are clean against p2.
        (Files that are clean against p1 are already not in files (unless
        full). This makes it possible to handle p2 clean files similarly.)
        """
        raise NotImplementedError
###END###
def getcommit(self, version):
        """Return the commit object for version"""
        raise NotImplementedError
###END###
def numcommits(self):
        """Return the number of commits in this source.

        If unknown, return None.
        """
        return None
###END###
def gettags(self):
        """Return the tags as a dictionary of name: revision

        Tag names must be UTF-8 strings.
        """
        raise NotImplementedError
###END###
def recode(self, s, encoding=None):
        if not encoding:
            encoding = self.encoding or b'utf-8'

        if isinstance(s, pycompat.unicode):
            return s.encode("utf-8")
        try:
            return s.decode(pycompat.sysstr(encoding)).encode("utf-8")
        except UnicodeError:
            try:
                return s.decode("latin-1").encode("utf-8")
            except UnicodeError:
                return s.decode(pycompat.sysstr(encoding), "replace").encode(
                    "utf-8"
                )
###END###
def getchangedfiles(self, rev, i):
        """Return the files changed by rev compared to parent[i].

        i is an index selecting one of the parents of rev.  The return
        value should be the list of files that are different in rev and
        this parent.

        If rev has no parents, i is None.

        This function is only needed to support --filemap
        """
        raise NotImplementedError
###END###
def converted(self, rev, sinkrev):
        '''Notify the source that a revision has been converted.'''
###END###
def hasnativeorder(self):
        """Return true if this source has a meaningful, native revision
        order. For instance, Mercurial revisions are store sequentially
        while there is no such global ordering with Darcs.
        """
        return False
###END###
def hasnativeclose(self):
        """Return true if this source has ability to close branch."""
        return False
###END###
def lookuprev(self, rev):
        """If rev is a meaningful revision reference in source, return
        the referenced identifier in the same format used by getcommit().
        return None otherwise.
        """
        return None
###END###
def getbookmarks(self):
        """Return the bookmarks as a dictionary of name: revision

        Bookmark names are to be UTF-8 strings.
        """
        return {}
###END###
def checkrevformat(self, revstr, mapname=b'splicemap'):
        """revstr is a string that describes a revision in the given
        source control system.  Return true if revstr has correct
        format.
        """
        return True
###END###
def __init__(self, ui, repotype, path):
        """Initialize conversion sink (or raise NoRepo("message")
        exception if path is not a valid repository)

        created is a list of paths to remove if a fatal error occurs
        later"""
        self.ui = ui
        self.path = path
        self.created = []
        self.repotype = repotype
###END###
def revmapfile(self):
        """Path to a file that will contain lines
        source_rev_id sink_rev_id
        mapping equivalent revision identifiers for each system."""
        raise NotImplementedError
###END###
def authorfile(self):
        """Path to a file that will contain lines
        srcauthor=dstauthor
        mapping equivalent authors identifiers for each system."""
        return None
###END###
def putcommit(
        self, files, copies, parents, commit, source, revmap, full, cleanp2
    ):
        """Create a revision with all changed files listed in 'files'
        and having listed parents. 'commit' is a commit object
        containing at a minimum the author, date, and message for this
        changeset.  'files' is a list of (path, version) tuples,
        'copies' is a dictionary mapping destinations to sources,
        'source' is the source repository, and 'revmap' is a mapfile
        of source revisions to converted revisions. Only getfile() and
        lookuprev() should be called on 'source'. 'full' means that 'files'
        is complete and all other files should be removed.
        'cleanp2' is a set of the filenames that are unchanged from p2
        (only in the common merge case where there two parents).

        Note that the sink repository is not told to update itself to
        a particular revision (or even what that revision would be)
        before it receives the file data.
        """
        raise NotImplementedError
###END###
def puttags(self, tags):
        """Put tags into sink.

        tags: {tagname: sink_rev_id, ...} where tagname is an UTF-8 string.
        Return a pair (tag_revision, tag_parent_revision), or (None, None)
        if nothing was changed.
        """
        raise NotImplementedError
###END###
def setbranch(self, branch, pbranches):
        """Set the current branch name. Called before the first putcommit
        on the branch.
        branch: branch name for subsequent commits
        pbranches: (converted parent revision, parent branch) tuples"""
###END###
def setfilemapmode(self, active):
        """Tell the destination that we're using a filemap

        Some converter_sources (svn in particular) can claim that a file
        was changed in a revision, even if there was no change.  This method
        tells the destination that we're using a filemap and that it should
        filter empty revisions.
        """
###END###
def before(self):
        pass
###END###
def after(self):
        pass
###END###
def putbookmarks(self, bookmarks):
        """Put bookmarks into sink.

        bookmarks: {bookmarkname: sink_rev_id, ...}
        where bookmarkname is an UTF-8 string.
        """
###END###
def hascommitfrommap(self, rev):
        """Return False if a rev mentioned in a filemap is known to not be
        present."""
        raise NotImplementedError
###END###
def hascommitforsplicemap(self, rev):
        """This method is for the special needs for splicemap handling and not
        for general use. Returns True if the sink contains rev, aborts on some
        special cases."""
        raise NotImplementedError
###END###
def __init__(self, ui, command):
        self.ui = ui
        self.command = command
###END###
def prerun(self):
        pass
###END###
def postrun(self):
        pass
###END###
def _cmdline(self, cmd, *args, **kwargs):
        kwargs = pycompat.byteskwargs(kwargs)
        cmdline = [self.command, cmd] + list(args)
        for k, v in pycompat.iteritems(kwargs):
            if len(k) == 1:
                cmdline.append(b'-' + k)
            else:
                cmdline.append(b'--' + k.replace(b'_', b'-'))
            try:
                if len(k) == 1:
                    cmdline.append(b'' + v)
                else:
                    cmdline[-1] += b'=' + v
            except TypeError:
                pass
        cmdline = [procutil.shellquote(arg) for arg in cmdline]
        if not self.ui.debugflag:
            cmdline += [b'2>', pycompat.bytestr(os.devnull)]
        cmdline = b' '.join(cmdline)
        return cmdline
###END###
def _run(self, cmd, *args, **kwargs):
        def popen(cmdline):
            p = subprocess.Popen(
                procutil.tonativestr(cmdline),
                shell=True,
                bufsize=-1,
                close_fds=procutil.closefds,
                stdout=subprocess.PIPE,
            )
            return p

        return self._dorun(popen, cmd, *args, **kwargs)
###END###
def _run2(self, cmd, *args, **kwargs):
        return self._dorun(procutil.popen2, cmd, *args, **kwargs)
###END###
def _run3(self, cmd, *args, **kwargs):
        return self._dorun(procutil.popen3, cmd, *args, **kwargs)
###END###
def _dorun(self, openfunc, cmd, *args, **kwargs):
        cmdline = self._cmdline(cmd, *args, **kwargs)
        self.ui.debug(b'running: %s\n' % (cmdline,))
        self.prerun()
        try:
            return openfunc(cmdline)
        finally:
            self.postrun()
###END###
def run(self, cmd, *args, **kwargs):
        p = self._run(cmd, *args, **kwargs)
        output = p.communicate()[0]
        self.ui.debug(output)
        return output, p.returncode
###END###
def runlines(self, cmd, *args, **kwargs):
        p = self._run(cmd, *args, **kwargs)
        output = p.stdout.readlines()
        p.wait()
        self.ui.debug(b''.join(output))
        return output, p.returncode
###END###
def checkexit(self, status, output=b''):
        if status:
            if output:
                self.ui.warn(_(b'%s error:\n') % self.command)
                self.ui.warn(output)
            msg = procutil.explainexit(status)
            raise error.Abort(b'%s %s' % (self.command, msg))
###END###
def run0(self, cmd, *args, **kwargs):
        output, status = self.run(cmd, *args, **kwargs)
        self.checkexit(status, output)
        return output
###END###
def runlines0(self, cmd, *args, **kwargs):
        output, status = self.runlines(cmd, *args, **kwargs)
        self.checkexit(status, b''.join(output))
        return output
###END###
def argmax(self):
        # POSIX requires at least 4096 bytes for ARG_MAX
        argmax = 4096
        try:
            argmax = os.sysconf("SC_ARG_MAX")
        except (AttributeError, ValueError):
            pass

        # Windows shells impose their own limits on command line length,
        # down to 2047 bytes for cmd.exe under Windows NT/2k and 2500 bytes
        # for older 4nt.exe. See http://support.microsoft.com/kb/830473 for
        # details about cmd.exe limitations.

        # Since ARG_MAX is for command line _and_ environment, lower our limit
        # (and make happy Windows shells while doing this).
        return argmax // 2 - 1
###END###
def _limit_arglist(self, arglist, cmd, *args, **kwargs):
        cmdlen = len(self._cmdline(cmd, *args, **kwargs))
        limit = self.argmax - cmdlen
        numbytes = 0
        fl = []
        for fn in arglist:
            b = len(fn) + 3
            if numbytes + b < limit or len(fl) == 0:
                fl.append(fn)
                numbytes += b
            else:
                yield fl
                fl = [fn]
                numbytes = b
        if fl:
            yield fl
###END###
def xargs(self, arglist, cmd, *args, **kwargs):
        for l in self._limit_arglist(arglist, cmd, *args, **kwargs):
            self.run0(cmd, *(list(args) + l), **kwargs)
###END###
def __init__(self, ui, path):
        super(mapfile, self).__init__()
        self.ui = ui
        self.path = path
        self.fp = None
        self.order = []
        self._read()
###END###
def _read(self):
        if not self.path:
            return
        try:
            fp = open(self.path, b'rb')
        except IOError as err:
            if err.errno != errno.ENOENT:
                raise
            return
        for i, line in enumerate(util.iterfile(fp)):
            line = line.splitlines()[0].rstrip()
            if not line:
                # Ignore blank lines
                continue
            try:
                key, value = line.rsplit(b' ', 1)
            except ValueError:
                raise error.Abort(
                    _(b'syntax error in %s(%d): key/value pair expected')
                    % (self.path, i + 1)
                )
            if key not in self:
                self.order.append(key)
            super(mapfile, self).__setitem__(key, value)
        fp.close()
###END###
def __setitem__(self, key, value):
        if self.fp is None:
            try:
                self.fp = open(self.path, b'ab')
            except IOError as err:
                raise error.Abort(
                    _(b'could not open map file %r: %s')
                    % (self.path, encoding.strtolocal(err.strerror))
                )
        self.fp.write(util.tonativeeol(b'%s %s\n' % (key, value)))
        self.fp.flush()
        super(mapfile, self).__setitem__(key, value)
###END###
def close(self):
        if self.fp:
            self.fp.close()
            self.fp = None
###END###
def __init__(self, url=b"", ra=None):
        self.pool = Pool()
        self.svn_url = url
        self.username = b''
        self.password = b''

        # Only Subversion 1.4 has reparent()
        if ra is None or not util.safehasattr(svn.ra, b'reparent'):
            self.client = svn.client.create_context(self.pool)
            ab = _create_auth_baton(self.pool)
            self.client.auth_baton = ab
            global svn_config
            if svn_config is None:
                svn_config = svn.core.svn_config_get_config(None)
            self.client.config = svn_config
            try:
                self.ra = svn.client.open_ra_session(
                    self.svn_url, self.client, self.pool
                )
            except SubversionException as xxx_todo_changeme:
                (inst, num) = xxx_todo_changeme.args
                if num in (
                    svn.core.SVN_ERR_RA_ILLEGAL_URL,
                    svn.core.SVN_ERR_RA_LOCAL_REPOS_OPEN_FAILED,
                    svn.core.SVN_ERR_BAD_URL,
                ):
                    raise NotBranchError(url)
                raise
        else:
            self.ra = ra
            svn.ra.reparent(self.ra, self.svn_url.encode('utf8'))
###END###
def do_update(self, revnum, path, *args, **kwargs):
        return self.Reporter(
            svn.ra.do_update(self.ra, revnum, path, *args, **kwargs)
        )
###END###
def __init__(self, reporter_data):
            self._reporter, self._baton = reporter_data
###END###
def set_path(self, path, revnum, start_empty, lock_token, pool=None):
            svn.ra.reporter2_invoke_set_path(
                self._reporter,
                self._baton,
                path,
                revnum,
                start_empty,
                lock_token,
                pool,
            )
###END###
def delete_path(self, path, pool=None):
            svn.ra.reporter2_invoke_delete_path(
                self._reporter, self._baton, path, pool
            )
###END###
def link_path(
            self, path, url, revision, start_empty, lock_token, pool=None
        ):
            svn.ra.reporter2_invoke_link_path(
                self._reporter,
                self._baton,
                path,
                url,
                revision,
                start_empty,
                lock_token,
                pool,
            )
###END###
def finish_report(self, pool=None):
            svn.ra.reporter2_invoke_finish_report(
                self._reporter, self._baton, pool
            )
###END###
def abort_report(self, pool=None):
            svn.ra.reporter2_invoke_abort_report(
                self._reporter, self._baton, pool
            )
###END###
def __init__(self, ui, repotype, path, revs=None):
        super(convert_cvs, self).__init__(ui, repotype, path, revs=revs)

        cvs = os.path.join(path, b"CVS")
        if not os.path.exists(cvs):
            raise NoRepo(_(b"%s does not look like a CVS checkout") % path)

        checktool(b'cvs')

        self.changeset = None
        self.files = {}
        self.tags = {}
        self.lastbranch = {}
        self.socket = None
        self.cvsroot = open(os.path.join(cvs, b"Root"), b'rb').read()[:-1]
        self.cvsrepo = open(os.path.join(cvs, b"Repository"), b'rb').read()[:-1]
        self.encoding = encoding.encoding

        self._connect()
###END###
def _parse(self):
        if self.changeset is not None:
            return
        self.changeset = {}

        maxrev = 0
        if self.revs:
            if len(self.revs) > 1:
                raise error.Abort(
                    _(
                        b'cvs source does not support specifying '
                        b'multiple revs'
                    )
                )
            # TODO: handle tags
            try:
                # patchset number?
                maxrev = int(self.revs[0])
            except ValueError:
                raise error.Abort(
                    _(b'revision %s is not a patchset number') % self.revs[0]
                )

        d = encoding.getcwd()
        try:
            os.chdir(self.path)

            cache = b'update'
            if not self.ui.configbool(b'convert', b'cvsps.cache'):
                cache = None
            db = cvsps.createlog(self.ui, cache=cache)
            db = cvsps.createchangeset(
                self.ui,
                db,
                fuzz=int(self.ui.config(b'convert', b'cvsps.fuzz')),
                mergeto=self.ui.config(b'convert', b'cvsps.mergeto'),
                mergefrom=self.ui.config(b'convert', b'cvsps.mergefrom'),
            )

            for cs in db:
                if maxrev and cs.id > maxrev:
                    break
                id = b"%d" % cs.id
                cs.author = self.recode(cs.author)
                self.lastbranch[cs.branch] = id
                cs.comment = self.recode(cs.comment)
                if self.ui.configbool(b'convert', b'localtimezone'):
                    cs.date = makedatetimestamp(cs.date[0])
                date = dateutil.datestr(cs.date, b'%Y-%m-%d %H:%M:%S %1%2')
                self.tags.update(dict.fromkeys(cs.tags, id))

                files = {}
                for f in cs.entries:
                    files[f.file] = b"%s%s" % (
                        b'.'.join([(b"%d" % x) for x in f.revision]),
                        [b'', b'(DEAD)'][f.dead],
                    )

                # add current commit to set
                c = commit(
                    author=cs.author,
                    date=date,
                    parents=[(b"%d" % p.id) for p in cs.parents],
                    desc=cs.comment,
                    branch=cs.branch or b'',
                )
                self.changeset[id] = c
                self.files[id] = files

            self.heads = self.lastbranch.values()
        finally:
            os.chdir(d)
###END###
def _connect(self):
        root = self.cvsroot
        conntype = None
        user, host = None, None
        cmd = [b'cvs', b'server']

        self.ui.status(_(b"connecting to %s\n") % root)

        if root.startswith(b":pserver:"):
            root = root[9:]
            m = re.match(r'(?:(.*?)(?::(.*?))?@)?([^:/]*)(?::(\d*))?(.*)', root)
            if m:
                conntype = b"pserver"
                user, passw, serv, port, root = m.groups()
                if not user:
                    user = b"anonymous"
                if not port:
                    port = 2401
                else:
                    port = int(port)
                format0 = b":pserver:%s@%s:%s" % (user, serv, root)
                format1 = b":pserver:%s@%s:%d%s" % (user, serv, port, root)

                if not passw:
                    passw = b"A"
                    cvspass = os.path.expanduser(b"~/.cvspass")
                    try:
                        pf = open(cvspass, b'rb')
                        for line in pf.read().splitlines():
                            part1, part2 = line.split(b' ', 1)
                            # /1 :pserver:user@example.com:2401/cvsroot/foo
                            # Ah<Z
                            if part1 == b'/1':
                                part1, part2 = part2.split(b' ', 1)
                                format = format1
                            # :pserver:user@example.com:/cvsroot/foo Ah<Z
                            else:
                                format = format0
                            if part1 == format:
                                passw = part2
                                break
                        pf.close()
                    except IOError as inst:
                        if inst.errno != errno.ENOENT:
                            if not getattr(inst, 'filename', None):
                                inst.filename = cvspass
                            raise

                sck = socket.socket()
                sck.connect((serv, port))
                sck.send(
                    b"\n".join(
                        [
                            b"BEGIN AUTH REQUEST",
                            root,
                            user,
                            passw,
                            b"END AUTH REQUEST",
                            b"",
                        ]
                    )
                )
                if sck.recv(128) != b"I LOVE YOU\n":
                    raise error.Abort(_(b"CVS pserver authentication failed"))

                self.writep = self.readp = sck.makefile(b'r+')

        if not conntype and root.startswith(b":local:"):
            conntype = b"local"
            root = root[7:]

        if not conntype:
            # :ext:user@host/home/user/path/to/cvsroot
            if root.startswith(b":ext:"):
                root = root[5:]
            m = re.match(br'(?:([^@:/]+)@)?([^:/]+):?(.*)', root)
            # Do not take Windows path "c:\foo\bar" for a connection strings
            if os.path.isdir(root) or not m:
                conntype = b"local"
            else:
                conntype = b"rsh"
                user, host, root = m.group(1), m.group(2), m.group(3)

        if conntype != b"pserver":
            if conntype == b"rsh":
                rsh = encoding.environ.get(b"CVS_RSH") or b"ssh"
                if user:
                    cmd = [rsh, b'-l', user, host] + cmd
                else:
                    cmd = [rsh, host] + cmd

            # popen2 does not support argument lists under Windows
            cmd = b' '.join(procutil.shellquote(arg) for arg in cmd)
            self.writep, self.readp = procutil.popen2(cmd)

        self.realroot = root

        self.writep.write(b"Root %s\n" % root)
        self.writep.write(
            b"Valid-responses ok error Valid-requests Mode"
            b" M Mbinary E Checked-in Created Updated"
            b" Merged Removed\n"
        )
        self.writep.write(b"valid-requests\n")
        self.writep.flush()
        r = self.readp.readline()
        if not r.startswith(b"Valid-requests"):
            raise error.Abort(
                _(
                    b'unexpected response from CVS server '
                    b'(expected "Valid-requests", but got %r)'
                )
                % r
            )
        if b"UseUnchanged" in r:
            self.writep.write(b"UseUnchanged\n")
            self.writep.flush()
            self.readp.readline()
###END###
def getheads(self):
        self._parse()
        return self.heads
###END###
def getfile(self, name, rev):
        def chunkedread(fp, count):
            # file-objects returned by socket.makefile() do not handle
            # large read() requests very well.
            chunksize = 65536
            output = stringio()
            while count > 0:
                data = fp.read(min(count, chunksize))
                if not data:
                    raise error.Abort(
                        _(b"%d bytes missing from remote file") % count
                    )
                count -= len(data)
                output.write(data)
            return output.getvalue()

        self._parse()
        if rev.endswith(b"(DEAD)"):
            return None, None

        args = (b"-N -P -kk -r %s --" % rev).split()
        args.append(self.cvsrepo + b'/' + name)
        for x in args:
            self.writep.write(b"Argument %s\n" % x)
        self.writep.write(b"Directory .\n%s\nco\n" % self.realroot)
        self.writep.flush()

        data = b""
        mode = None
        while True:
            line = self.readp.readline()
            if line.startswith(b"Created ") or line.startswith(b"Updated "):
                self.readp.readline()  # path
                self.readp.readline()  # entries
                mode = self.readp.readline()[:-1]
                count = int(self.readp.readline()[:-1])
                data = chunkedread(self.readp, count)
            elif line.startswith(b" "):
                data += line[1:]
            elif line.startswith(b"M "):
                pass
            elif line.startswith(b"Mbinary "):
                count = int(self.readp.readline()[:-1])
                data = chunkedread(self.readp, count)
            else:
                if line == b"ok\n":
                    if mode is None:
                        raise error.Abort(_(b'malformed response from CVS'))
                    return (data, b"x" in mode and b"x" or b"")
                elif line.startswith(b"E "):
                    self.ui.warn(_(b"cvs server: %s\n") % line[2:])
                elif line.startswith(b"Remove"):
                    self.readp.readline()
                else:
                    raise error.Abort(_(b"unknown CVS response: %s") % line)
###END###
def getchanges(self, rev, full):
        if full:
            raise error.Abort(_(b"convert from cvs does not support --full"))
        self._parse()
        return sorted(pycompat.iteritems(self.files[rev])), {}, set()
###END###
def getcommit(self, rev):
        self._parse()
        return self.changeset[rev]
###END###
def gettags(self):
        self._parse()
        return self.tags
###END###
def getchangedfiles(self, rev, i):
        self._parse()
        return sorted(self.files[rev])
###END###
def generate(self, commonrevs, clnodes, fastpathlinkrev, source, **kwargs):
        if shallowutil.isenabled(self._repo):
            fastpathlinkrev = False

        return super(shallowcg1packer, self).generate(
            commonrevs, clnodes, fastpathlinkrev, source, **kwargs
        )
###END###
def group(self, nodelist, rlog, lookup, units=None, reorder=None):
        return shallowgroup(
            shallowcg1packer, self, nodelist, rlog, lookup, units=units
        )
###END###
def generatefiles(self, changedfiles, *args, **kwargs):
        try:
            linknodes, commonrevs, source = args
        except ValueError:
            commonrevs, source, mfdicts, fastpathlinkrev, fnodes, clrevs = args
        if shallowutil.isenabled(self._repo):
            repo = self._repo
            if isinstance(repo, bundlerepo.bundlerepository):
                # If the bundle contains filelogs, we can't pull from it, since
                # bundlerepo is heavily tied to revlogs. Instead require that
                # the user use unbundle instead.
                # Force load the filelog data.
                bundlerepo.bundlerepository.file(repo, b'foo')
                if repo._cgfilespos:
                    raise error.Abort(
                        b"cannot pull from full bundles",
                        hint=b"use `hg unbundle` instead",
                    )
                return []
            filestosend = self.shouldaddfilegroups(source)
            if filestosend == NoFiles:
                changedfiles = list(
                    [f for f in changedfiles if not repo.shallowmatch(f)]
                )

        return super(shallowcg1packer, self).generatefiles(
            changedfiles, *args, **kwargs
        )
###END###
def shouldaddfilegroups(self, source):
        repo = self._repo
        if not shallowutil.isenabled(repo):
            return AllFiles

        if source == b"push" or source == b"bundle":
            return AllFiles

        # We won't actually strip the files, but we should put them in any
        # backup bundle generated by strip (especially for cases like narrow's
        # `hg tracked --removeinclude`, as failing to do so means that the
        # "saved" changesets during a strip won't have their files reapplied and
        # thus their linknode adjusted, if necessary).
        if source == b"strip":
            cfg = repo.ui.config(b'remotefilelog', b'strip.includefiles')
            if cfg == b'local':
                return LocalFiles
            elif cfg != b'none':
                return AllFiles

        caps = self._bundlecaps or []
        if source == b"serve" or source == b"pull":
            if constants.BUNDLE2_CAPABLITY in caps:
                return LocalFiles
            else:
                # Serving to a full repo requires us to serve everything
                repo.ui.warn(_(b"pulling from a shallow repo\n"))
                return AllFiles

        return NoFiles
###END###
def prune(self, rlog, missing, commonrevs):
        if not isinstance(rlog, remotefilelog.remotefilelog):
            return super(shallowcg1packer, self).prune(
                rlog, missing, commonrevs
            )

        repo = self._repo
        results = []
        for fnode in missing:
            fctx = repo.filectx(rlog.filename, fileid=fnode)
            if fctx.linkrev() not in commonrevs:
                results.append(fnode)
        return results
###END###
def nodechunk(self, revlog, node, prevnode, linknode):
        prefix = b''
        if prevnode == revlog.nullid:
            delta = revlog.rawdata(node)
            prefix = mdiff.trivialdiffheader(len(delta))
        else:
            # Actually uses remotefilelog.revdiff which works on nodes, not revs
            delta = revlog.revdiff(prevnode, node)
        p1, p2 = revlog.parents(node)
        flags = revlog.flags(node)
        meta = self.builddeltaheader(node, p1, p2, prevnode, linknode, flags)
        meta += prefix
        l = len(meta) + len(delta)
        yield changegroup.chunkheader(l)
        yield meta
        yield delta
###END###
